{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2023-09-20T01:57:40.372181Z","iopub.execute_input":"2023-09-20T01:57:40.372501Z","iopub.status.idle":"2023-09-20T01:57:47.432858Z","shell.execute_reply.started":"2023-09-20T01:57:40.372472Z","shell.execute_reply":"2023-09-20T01:57:47.430751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U tensorflow-addons","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 2\ninput_shape = (256, 256, 1)\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\ndef load_and_preprocess_image(image_path,image_size=(256,256)):\n    image = cv2.imread(image_path)\n    # Convert to grayscale\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    # Resize to the desired image size\n    resized_image = cv2.resize(gray_image, image_size)\n    # Reshape to (64, 64, 1) for grayscale\n    reshaped_image = resized_image.reshape((*image_size, 1))\n    # Normalize pixel values to [0, 1]\n    normalized_image = reshaped_image / 255.0\n    return normalized_image\n\ndef parse_data(root_directory,image_size = (256,256)):\n    # Initialize empty lists to store image data and labels\n    x = []\n    y = []\n\n    # Traverse the directory tree\n    for root, dire, _ in os.walk(root_directory):\n        for d in dire:\n            subdir = os.path.join(root,d)\n            if subdir.split('/')[-1] == 'AC':\n                label = 1  # Positive class\n            elif subdir.split('/')[-1] == 'NC':\n                label = 0  # Negative class\n            else:\n                continue  # Skip other directories\n            for _,_,filenames in os.walk(subdir):\n                for fn in filenames:\n                    # Get the full path of the image file            \n                    image_path = os.path.join(subdir, fn)\n                    # Load and preprocess the image\n                    image_data = load_and_preprocess_image(image_path)\n\n                    # Append the data and label to the lists\n                    x.append(image_data)\n                    y.append(label)\n\n    # Convert the lists to numpy arrays\n    x = np.array(x)\n    y = np.array(y)\n    return (x,y)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-20T02:18:49.278598Z","iopub.execute_input":"2023-09-20T02:18:49.279168Z","iopub.status.idle":"2023-09-20T02:18:49.287515Z","shell.execute_reply.started":"2023-09-20T02:18:49.279138Z","shell.execute_reply":"2023-09-20T02:18:49.286398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/adni-preprocessed/AD_NC/train/'\ntest_dir = '/kaggle/input/adni-preprocessed/AD_NC/test/'\n(x_train,y_train) = parse_data(train_dir,image_size = (256,256))\n(x_test,y_test) = parse_data(test_dir,image_size = (256,256))","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:19:36.817233Z","iopub.execute_input":"2023-09-20T02:19:36.818976Z","iopub.status.idle":"2023-09-20T02:20:22.375371Z","shell.execute_reply.started":"2023-09-20T02:19:36.818908Z","shell.execute_reply":"2023-09-20T02:20:22.373574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\nprint(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-20T02:20:22.405160Z","iopub.execute_input":"2023-09-20T02:20:22.405483Z","iopub.status.idle":"2023-09-20T02:20:22.418114Z","shell.execute_reply.started":"2023-09-20T02:20:22.405449Z","shell.execute_reply":"2023-09-20T02:20:22.416350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nim=plt.imread(\"/kaggle/input/adni-preprocessed/AD_NC/test/NC/1215566_102.jpeg\")\nplt.imshow(im,cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T01:57:47.435089Z","iopub.execute_input":"2023-09-20T01:57:47.435400Z","iopub.status.idle":"2023-09-20T01:57:47.623427Z","shell.execute_reply.started":"2023-09-20T01:57:47.435376Z","shell.execute_reply":"2023-09-20T01:57:47.622496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}