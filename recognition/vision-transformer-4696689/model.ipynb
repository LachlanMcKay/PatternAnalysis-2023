{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "206e485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"numpy and torch\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\"\"\"PIL\"\"\"\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"torchvision and utils\"\"\"\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\"\"\"os\"\"\"\n",
    "import os\n",
    "\n",
    "\n",
    "\"\"\"Get image to tensor\"\"\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "\"\"\"Loading data into arrays\"\"\"\n",
    "xtrain, xtrain, xtest, ytest = [], [], [], []\n",
    "\n",
    "\"\"\"training data\"\"\"\n",
    "trainDIRs = ['../../../AD_NC/train/AD/', '../../../AD_NC/train/NC']\n",
    "size = [0, 0]\n",
    "for i, DIR in enumerate(trainDIRs):\n",
    "    for filename in os.listdir(DIR):\n",
    "        f = os.path.join(DIR, filename)\n",
    "        img = Image.open(f)\n",
    "        tensor = transform(img).float()\n",
    "        tensor.require_grad = True\n",
    "        xtrain.append(tensor/255)\n",
    "        size[i] += 1\n",
    "xtrain = torch.stack(xtrain)\n",
    "ytrain = torch.from_numpy(np.concatenate((np.ones(size[0]), np.zeros(size[1])), axis=0))\n",
    "\n",
    "\"\"\"testing data\"\"\"\n",
    "testDIRs = ['../../../AD_NC/test/AD/', '../../../AD_NC/test/NC']\n",
    "size = [0, 0]\n",
    "for i, DIR in enumerate(testDIRs):\n",
    "    for filename in os.listdir(DIR):\n",
    "        f = os.path.join(DIR, filename)\n",
    "        img = Image.open(f)\n",
    "        tensor = transform(img).float()\n",
    "        tensor.require_grad = True\n",
    "        xtest.append(tensor/255)\n",
    "        size[i] += 1\n",
    "xtest = torch.stack(xtest)\n",
    "ytest = torch.from_numpy(np.concatenate((np.ones(size[0]), np.zeros(size[1])), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4ae7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posEmbedding(imgs, wsize, hsize):\n",
    "    N, C, W, H = imgs.shape #number imgs, channels, width, height\n",
    "    size = (N, C, W // wsize, wsize, H // hsize, hsize)\n",
    "    perm = (0, 2, 4, 1, 3, 5) #bring col, row index of patch to front\n",
    "    flat = (1, 2) #flatten (col, row) index into col*row entry index for patches\n",
    "    imgs = imgs.reshape(size).permute(perm).flatten(*flat)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8fb7b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = posEmbedding(xtrain, 16, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
