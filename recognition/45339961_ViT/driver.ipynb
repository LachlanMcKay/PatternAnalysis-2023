{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda (NVIDIA GeForce RTX 3060 Laptop GPU)\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import AdamW, SGD\n",
    "from torchinfo import summary\n",
    "from modules import ViT\n",
    "from dataset import create_dataloaders\n",
    "from utils import get_transform, plot_losses_accuracies\n",
    "from train import train, test\n",
    "from predict import predict\n",
    "\n",
    "if not os.path.exists(config.results_path):\n",
    "    os.makedirs(config.results_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# Check whether image shape is divisible by patch size\n",
    "assert config.image_size % config.patch_size == 0, print(\"Image Width is not divisible by patch size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ininitialise transforms\n",
    "train_transform = get_transform(data_type=\"train\",\n",
    "                                data_mean=config.train_mean,\n",
    "                                data_std=config.train_std,\n",
    "                                image_size=config.image_size)\n",
    "\n",
    "valid_transform = get_transform(data_type=\"valid\",\n",
    "                                data_mean=config.train_mean,\n",
    "                                data_std=config.train_std,\n",
    "                                image_size=config.image_size)\n",
    "\n",
    "test_transform = get_transform(data_type=\"test\",\n",
    "                                data_mean=config.test_mean,\n",
    "                                data_std=config.test_std,\n",
    "                                image_size=config.image_size)\n",
    "\n",
    "# Setup dataloaders\n",
    "root_dir = config.data_path\n",
    "train_loader, valid_loader, test_loader = create_dataloaders(root_dir, \n",
    "                                                            train_transform,\n",
    "                                                            valid_transform,\n",
    "                                                            test_transform,\n",
    "                                                            batch_size=config.batch_size,\n",
    "                                                            datasplit=config.data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model\n",
    "if config.will_load:\n",
    "    model = torch.load(config.load_path)\n",
    "else:\n",
    "    model = ViT(img_size=config.image_size,\n",
    "                in_channels=config.n_channels,\n",
    "                patch_size=config.patch_size,\n",
    "                num_classes=config.n_classes,\n",
    "                num_transformer_layers=config.n_layers,\n",
    "                embedding_dim=config.embedding_dim,\n",
    "                mlp_size=config.mlp_size,\n",
    "                num_heads=config.n_heads,\n",
    "                attn_dropout=config.attn_dropout,\n",
    "                mlp_dropout=config.mlp_dropout,\n",
    "                embedding_dropout=config.embedding_dropout)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Show model summary\n",
    "if config.show_model_summary:\n",
    "    summary(model=model,\n",
    "        input_size=(config.batch_size,\n",
    "                    config.n_channels,\n",
    "                    config.image_size,\n",
    "                    config.image_size),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [31:05<00:00, 124.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialise loss function and optimiser\n",
    "# optimizer = AdamW(model.parameters(), \n",
    "#             lr=config.learning_rate)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if config.will_train:\n",
    "    # Train the model\n",
    "    train_accuracies, valid_accuracies, train_losses, valid_losses = train(model=model,\n",
    "                                                                        train_loader=train_loader,\n",
    "                                                                        valid_loader=valid_loader,\n",
    "                                                                        criterion=criterion,\n",
    "                                                                        optimizer=optimizer,\n",
    "                                                                        device=device,\n",
    "                                                                        n_epochs=config.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 141/141 [00:48<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.65\n",
      "Test accuracy: 67.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "if config.will_test:\n",
    "    test(model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
