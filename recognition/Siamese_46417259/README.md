# Identification of Alzheimer's Disease in Brain Scans Using a Siamese Neural Network
Project by Minhao Sun. 

This project is a part of the University of Queensland's COMP3710: Pattern Recognition and Analysis course in Semester 2, 2023.

# Project Introduction
Here is a placeholder

a description of the algorithm and the problem that it solves
(approximately a paragraph), how it works in a paragraph and a figure/visualisation

name drop pytorch

## Project files and usage
The project contains the following files:
* `dataset.py`: contains code for preprocessing and loading data
* `modules.py`: contains the components of the models used in this project
* `predict.py`: contains code demonstrating example usage of a trained model
* `train.py`: contains code for training, validating and testing of the models
* `utils.py`: contains code for loading and saving the models
* `CONSTANTS.py`: defines global constants for filepaths to be used in the project
* `BSD_new.txt`: see the section ***Open Source Acknowledgement and Licences***
* `README.md`: this README


## Defined Terms
The following terms in this README are given specific meanings: 
* torch: Pytorch
* `nn`: Pytorch's Neural Network module, `torch.nn` 

&nbsp;


# The Models
The project makes use of three models which are located in `modules.py` and inherit from `nn.Module`. The models are:

## The Siamese Backbone / Embedding Network
This is the network used to generate the embeddings used by both the overall the Siamese Network and the classifier. It is defined in the class `SiameseTwin`.

### The final model architecture
The embedding network used in this project closely follows the architecture proposed by Koch, Zemel and Salakhutdinov<sup>1</sup>. The size of the layers are modified to suit the image size of the (transformed) ADNI dataset. The network architecture is illustrated in the diagram below:

![Diagram of the network architecture of the embedding network](assets/Embedding_network_diagram.png)
<sub>The network architecture of the embedding network</sub>

### Other architecture attempted
The project also experimented with two other embedding network architectures. 
First, the project attempted to use the embedding network architecture proposed by Liu et al<sup>2</sup>. Briefly, the proposed embedding network can be described as a 6-layer fully-connected neural network with 1024 nodes per layer. However, the architecture did not perform as well as the Koch, Zemel and Salakhutdinov architecture in testing, both in terms of loss and in terms of final classifier accuracy. Therefore, the architecture was not adopted. 

The project has also attempted to use VGG16 with minor modifications as its embedding network. The general structure of the VGG16 network is well documented<sup>3</sup>, and the only modification made to the general VGG16 structure was in the final fully-connected layers such that the network generated a feature vector instead of a classifier output. Ultimately, the VGG16 embedding network performed similarly to the Koch, Zemel and Salakhutdinov architecture in testing in terms of loss and final accuracy. It was not adopted because VGG16 took longer to train compared to the Koch, Zemel and Salakhutdinov architecture. 

## The Overall Siamese Network
The overall Siamese network used in this project is defined in the class `SiameseNeuralNet`. Its architecture is illustrated in the diagram below. 

![Diagram of the network architecture of the overall Siamese network](assets/Siamese_diagram.png)
<sub>The network architecture of the overall Siamese network</sub>

## The Classification Network
The classifier used in this project is defined in the class `SimpleMLP`. It performs binary classification on the embeddings generated by the Siamese backbone. 
As the name suggests, the final model architechure is a simple multi-layer perceptron. The network contains four fully-connected layers and its architecture is illustrated in the diagram below:

![Diagram of the network architecture of the classifier](assets/Classifier_diagram.png)
<sub>The network architecture of the classifier</sub>

# The Dataset and Preprocessing
The project uses the Alzheimerâ€™s Disease Neuroimaging Initiative (ADNI) brain dataset, which consists of brain scans of people suffering from Alzheimer's disease and brain scans of cognitive normal people. Images contain 3 channels and are of 256 pixels wide by 240 pixels high. The dataloading functionality of the project is implemented in `dataset.py`.

> [!NOTE]
> The file paths to the dataset are configurable via `CONSTANTS.py`.


## Training / Validation / Test Split
The ADNI dataset is provided in two subfolders: `train` (21520 images) and `test` (9000 images). 
The images in the `test` folder form the project's testing set. 
The images in the `train` folder are split on the patient level to form the project's training and validation sets. 

By default, the images of 80% of the unique patients in the `train` folder are assigned to the project's training set, and the images of the remaining 20% of the unique patients are assigned to the project's validation set. The proportion of the training and validation split is adjustable by passing a parameter to the `load_data` method in `dataset.py`.

## Transforms
Different transforms were applied to the datasets depending on their category. 
The validation and test data was converted to `Tensor` and then centre-cropped to a square image of 240 pixels wide by 240 pixels high.

In contrast, the training data was converted to `Tensor`. 20 black pixels were padded to all sides of the image, then the image is randomly cropped to a square image of 240 pixels wide by 240 pixels high.
Effectively, the test transforms amount to a random horizontal translation of each image by up to 20 pixels in each direction (in addition to resizing). This was used as a data augmentation technique and improved classification accuracy from ~65% to ~77%. Classification accuracy will be discussed further in later sections of this report.

## Pairing of Images for the Siamese Network
The Siamese network used in this project requires paired images to train. In addition, the image pairs must be accompanied by a label indicating whether or not the two images are of the same class. 

A custom dataset called `PairedDataset` was made to handle the pairing of images for the Siamese network. It wraps an existing dataset, expected to be of type `torch.utils.data.Subset` and retains that dataset's length. 
Image pairings are generated randomly such that for any given image in the dataset, it has a 50% chance of being paired up with an image of the same class and a 50% chance of being paired up with an image of the different class. The pairs are then labelled accordingly. 

## Visualisation Options
The function `test_visualise_data_MLP` allows for the visualisation of the data used to train/validate/test the MLP. A sample output is provided below: 

![Sample batch containing 15 images that are used to validate the MLP with labels presented in human-readable form](assets/data_for_mlp.png)
<sub>Sample batch containing 15 images that are used to validate the MLP with labels presented in human-readable form (note the absence of translation transforms)</sub>

The function `test_visualise_data_Siamese` allows for the visualisation of the data used to train/validate/test the Siamese network. A sample output is provided below. 
Note that the visualisation includes the last 15 characters of each image's filepath (excluding file extension). This was added to check that the same/different labels are applied correctly.

![Sample batch containing 9 paired images that are used to train the Siamese network with labels presented in human-readable form](assets/data_for_Siamese.png)
<sub>Sample batch containing 9 paired images that are used to train the Siamese network with labels presented in human-readable form (note the presence of translation transforms)</sub>

# Training and Validating the Models
The training and validation of the models are implemented in `train.py`. Two different training workflows are implemented. These are:
* A sequential training workflow where the Siamese network is trained for a specified number of epochs, then the embedding network at the last epoch is used to train the classifier
* A modular training workflow where the classifer is trained based on any pretrained and saved embedding network.

> [!NOTE]
> All plots in this section were produced with a seed of 35 for both python's `random` module and Pytorch's inbuilt pseudo-random number generator. 

## Siamese Training for the Embedding Network 
### Loss Function
As the Siamese network used in this project is designed for paired images, the contrastive loss function was used. The contrastive loss function is defined as:

$L = Y * ||x_i-y_j||^2 + (1-Y) * \max(0, m-||x_i-y_j||^2)$

where $Y$ is the label indicating whether the two images are of the same class, $x_i$ is the embedding(s) of the first image, $y_j$ is the embedding(s) of the second image, and $m$ is the margin. The loss function is implemented in the class `ContrastiveLoss` and is partially adopted from an existing implementation by Anurag Singh Choudhary<sup>3</sup>.

### Optimiser
Adam was used as the optimiser for the Siamese network with a learning rate of 0.0001 and betas of (0.5, 0.999). During testing, this confirguration was found to deliver the best performance in terms of loss and final accuracy. Weight decay and learning rate schedulers were tested, but were found to not improve the performance of the model.

### Results
Ultimately, it was found that 15 epochs of Siamese training for the embedding network resulted in the best classifier accuracy regardless of the number of epochs used to train the classifier.
This is despite the fact that the Siamese network appears to overfit the training data after 8 to 10 epochs of training in the loss plot below. 

![Training and validation loss plot for the overall Siamese network, showing validation loss diverging from training loss from around epochs 8 to 10](assets/Siamese_loss_after_15_epochs.png)
<sub>Training and validation loss plot for the overall Siamese network</sub>


## Training for the Classification Network
### Loss Function
As the classifier is performing a binary classification task, binary cross-entropy loss was used.

### Optimiser
Adam was used as the optimiser for the classifier with a learning rate of 0.001 and betas of (0.5, 0.999). During testing, this confirguration was found to deliver the best performance in terms of loss and final accuracy. Weight decay and learning rate schedulers were tested, but were found to not improve the performance of the model.

### Results
The classifier was trained for 20 epochs. The training and validation loss plot is shown below. Both the training and validation losses appear to stabilise in the second epoch (epoch 1) and remain at approximately the same level throughout all remaining epochs. Comparatively, the validation set has a greater range of variation.

![Training and validation loss plot for the classification network, showing both training and validation loss remaining at approximately the same level throughout epochs 1-19](assets/Classifier_loss_after_20_epochs.png)
<sub>Training and validation loss plot for the classification network</sub>

The classifier's accuracy for both the validation set and the test set is shown below. Consistent with the loss plot, the accuracy of the classifier appears to remain stable throughout all epochs. Comparatively, the testing set has a greater range of variation. **Ultimately, the best accuracy achieved by the classifier on the test set is FILL THIS IN%.**

![Plot of the classifier's accuracy on the validation and test datasets, showing both accuracies to remain relatively stable throughout all 20 epochs](assets/Classifier_Accuracy_after_20_epochs.png)
<sub>Plot of the classifier's accuracy on the validation and test datasets</sub>

# Discussion of Results 

# Using the Models for Classification
put some images here

# Project Dependencies
This project is developed in the following environment:
* Python 3.11.4 
* Pytorch
* NumPy
* Matplotlib

probably some more stuff


# References
[1]: Koch, Zemel and Salakhutdinov (the oneshot paper)

[2]: Liu et al (the other paper)

[3] https://www.analyticsvidhya.com/blog/2023/08/introduction-and-implementation-of-siamese-networks/#:~:text=Binary%20Cross%2DEntropy%20Loss,-Binary%20cross%2Dentropy&text=In%20the%20context%20of%20a,class%20and%20the%20actual%20outcome.

## Open Source Acknowledgement and Licences
