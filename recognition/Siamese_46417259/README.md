# Identification of Alzheimer's Disease in Brain Scans Using a Siamese Neural Network
Project by Minhao Sun. 

This project is a part of the University of Queensland's COMP3710: Pattern Recognition and Analysis course in Semester 2, 2023.

# Project Introduction
Here is a placeholder

name drop pytorch

## Project files and usage
The project contains the following files:
* `dataset.py`: contains code for preprocessing and loading data
* `modules.py`: contains the components of the models used in this project
* `predict.py`: contains code demonstrating example usage of a trained model
* `train.py`: contains code for training, validating and testing of the models
* `utils.py`: contains code for loading and saving the models
* `CONSTANTS.py`: defines global constants for filepaths to be used in the project
* `BSD_new.txt`: see the section ***Open Source Acknowledgement and Licences***
* `README.md`: this README


## Defined Terms
The following terms in this README are given specific meanings: 
* torch: Pytorch
* `nn`: Pytorch's Neural Network module, `torch.nn` 

&nbsp;


# The Models
The project makes use of three models which are located in `modules.py` and inherit from `nn.Module`. The models are:

## The Siamese Backbone / Embedding Network
This is the network used to generate the embeddings used by both the overall the Siamese Network and the classifier. It is defined in the class `SiameseTwin`.

### The final model architecture
The embedding network used in this project closely follows the architecture proposed by Koch, Zemel and Salakhutdinov<sup>1</sup>. The size of the layers are modified to suit the image size of the ADNI dataset. The network architecture is illustrated in the diagram below:

Insert diagram here 

### Other architecture attempted
The project also experimented with two other embedding network architectures. 
First, the project attempted to use the embedding network architecture proposed by Liu et al<sup>2</sup>. Briefly, the proposed embedding network can be described as a 6-layer fully-connected neural network with 1024 nodes per layer. However, the architecture did not perform as well as the Koch, Zemel and Salakhutdinov architecture in testing, both in terms of loss and in terms of final classifier accuracy. Therefore, the architecture was not adopted. 

The project has also attempted to use VGG16 with minor modifications as its embedding network. The general structure of the VGG16 network is well documented<sup>3</sup>, and the only modification made to the general VGG16 structure was in the final fully-connected layers such that the network generated a feature vector instead of a classifier output. Ultimately, the VGG16 embedding network performed similarly to the Koch, Zemel and Salakhutdinov architecture in testing in terms of loss and final accuracy. It was not adopted because VGG16 took longer to train compared to the Koch, Zemel and Salakhutdinov architecture. 

## The Overall Siamese Network
The overall Siamese network used in this project is defined in the class `SiameseNeuralNet`. Its architecture is illustrated in the diagram below. 

insert diagram here

## The Classification Network
The classifier used in this project is defined in the class `SimpleMLP`. It performs binary classification on the embeddings generated by the Siamese backbone. 
As the name suggests, the final model architechure is a simple multi-layer perceptron. The network contains four fully-connected layers and its architecture is illustrated in the diagram below:

insert diagram here

# The Dataset and Preprocessing
The project uses the Alzheimerâ€™s Disease Neuroimaging Initiative (ADNI) brain dataset, which consists of brain scans of people suffering from Alzheimer's disease and brain scans of cognitive normal people. Images contain 3 channels and are of 256 pixels wide by 240 pixels high. The file path to the training images are configurable via `CONSTANTS.py` and will be discussed in more detail later. The dataloading functionality of the project is implemented in `dataset.py`.

## Training / Validation / Test Split
The ADNI dataset is provided in two subfolders: `train` (21520 images) and `test` (9000 images). 
The images in the `test` folder form the project's testing set. 
The images in the `train` folder are split on the patient level to form the project's training and validation sets. 

By default, the images of 80% of the unique patients in the `train` folder are assigned to the project's training set, and the images of the remaining 20% of the unique patients are assigned to the project's validation set. The proportion of the training and validation split is adjustable by passing a parameter to the `load_data` method in `dataset.py`.

## Transforms
Different transforms were applied to the datasets depending on their category. 
The validation and test data was converted to `Tensor` and then centre-cropped to a square image of 240 pixels wide by 240 pixels high.

In contrast, the training data was converted to `Tensor`. 20 black pixels were padded to all sides of the image, then the image is randomly cropped to a square image of 240 pixels wide by 240 pixels high.
Effectively, the test transforms amount to a random horizontal translation of each image by up to 20 pixels in each direction (in addition to resizing). This was used as a data augmentation technique and improved classification accuracy from ~65% to ~77%. Classification accuracy will be discussed further in later sections of this report.

## Pairing of Images for the Siamese Network
The Siamese network used in this project requires paired images to train. In addition, the image pairs must be accompanied by a label indicating whether or not the two images are of the same class. 

A custom dataset called `PairedDataset` was made to handle the pairing of images for the Siamese network. It wraps an existing dataset, expected to be of type `torch.utils.data.Subset` and retains that dataset's length. 
Image pairings are generated randomly such that for any given image in the dataset, it has a 50% chance of being paired up with an image of the same class and a 50% chance of being paired up with an image of the different class. The pairs are then labelled accordingly. 

## Visualisation Options
The function `test_visualise_data_MLP` allows for the visualisation of the data used to train/validate/test the MLP. A sample output is provided below: 

![Sample batch containing 15 images that are used to validate the MLP with labels presented in human-readable form](assets/data_for_mlp.png)
<sub>Sample batch containing 15 images that are used to validate the MLP with labels presented in human-readable form (note the absence of translation transforms)</sub>

&nbsp;

The function `test_visualise_data_Siamese` allows for the visualisation of the data used to train/validate/test the Siamese network. A sample output is provided below. 
Note that the visualisation includes the last 15 characters of each image's filepath (excluding file extension). This was added to check that the same/different labels are applied correctly.

![Sample batch containing 9 paired images that are used to train the Siamese network with labels presented in human-readable form](assets/data_for_Siamese.png)
<sub>Sample batch containing 9 paired images that are used to train the Siamese network with labels presented in human-readable form (note the presence of translation transforms)</sub>

&nbsp;

# Training and Validating the Models

## Siamese Training for the Embedding Network 
put some plots here
reproducibility

### Loss Function
### Optimiser
### Learning Rate Scheduler Not Used

## Classifier Training


# Using the Models for Classification
put some images here



# Dependencies
* Python 3.11.4 
* Pytorch
* NumPy
* Matplotlib

probably some more stuff


# References
[1]: Koch, Zemel and Salakhutdinov (the oneshot paper)

[2]: Liu et al (the other paper)

## Open Source Acknowledgement and Licences
