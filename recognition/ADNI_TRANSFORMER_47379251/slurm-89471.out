2023-10-10 08:23:52.833853: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-10 08:23:54.122615: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
==> Preparing data..
==> Building model..
ViT(
  (to_patch_embedding): SPT(
    (to_patch_tokens): Sequential(
      (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=128, p2=128)
      (1): LayerNorm((245760,), eps=1e-05, elementwise_affine=True)
      (2): Linear(in_features=245760, out_features=512, bias=True)
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (transformer): Transformer(
    (layers): ModuleList(
      (0-3): 4 x ModuleList(
        (0): LSA(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attend): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (to_qkv): Linear(in_features=512, out_features=768, bias=False)
          (to_out): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): Dropout(p=0.3, inplace=False)
          )
        )
        (1): FeedForward(
          (net): Sequential(
            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=512, out_features=1024, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.3, inplace=False)
            (4): Linear(in_features=1024, out_features=512, bias=True)
            (5): Dropout(p=0.3, inplace=False)
          )
        )
      )
    )
  )
  (to_latent): Identity()
  (mlp_head): Sequential(
    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=512, out_features=2, bias=True)
  )
)
Training..
ViT(
  (to_patch_embedding): SPT(
    (to_patch_tokens): Sequential(
      (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=128, p2=128)
      (1): LayerNorm((245760,), eps=1e-05, elementwise_affine=True)
      (2): Linear(in_features=245760, out_features=512, bias=True)
    )
  )
  (dropout): Dropout(p=0.3, inplace=False)
  (transformer): Transformer(
    (layers): ModuleList(
      (0-3): 4 x ModuleList(
        (0): LSA(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attend): Softmax(dim=-1)
          (dropout): Dropout(p=0.3, inplace=False)
          (to_qkv): Linear(in_features=512, out_features=768, bias=False)
          (to_out): Sequential(
            (0): Linear(in_features=256, out_features=512, bias=True)
            (1): Dropout(p=0.3, inplace=False)
          )
        )
        (1): FeedForward(
          (net): Sequential(
            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=512, out_features=1024, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.3, inplace=False)
            (4): Linear(in_features=1024, out_features=512, bias=True)
            (5): Dropout(p=0.3, inplace=False)
          )
        )
      )
    )
  )
  (to_latent): Identity()
  (mlp_head): Sequential(
    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=512, out_features=2, bias=True)
  )
)

Epoch: 0
graph(%self.1 : __torch__.vit_pytorch.vit_for_small_dataset.ViT,
      %img : Float(128, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=0, device=cuda:0)):
  %mlp_head : __torch__.torch.nn.modules.container.___torch_mangle_66.Sequential = prim::GetAttr[name="mlp_head"](%self.1)
  %to_latent : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name="to_latent"](%self.1)
  %transformer : __torch__.vit_pytorch.vit_for_small_dataset.Transformer = prim::GetAttr[name="transformer"](%self.1)
  %dropout.1 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.1)
  %pos_embedding : Tensor = prim::GetAttr[name="pos_embedding"](%self.1)
  %cls_token : Tensor = prim::GetAttr[name="cls_token"](%self.1)
  %to_patch_embedding : __torch__.vit_pytorch.vit_for_small_dataset.SPT = prim::GetAttr[name="to_patch_embedding"](%self.1)
  %1700 : int = prim::Constant[value=5](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:42:0
  %1701 : int = prim::Constant[value=4](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:42:0
  %1702 : int = prim::Constant[value=128](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:70:0
  %1703 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16384}](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1704 : Long(requires_grad=0, device=cpu) = prim::Constant[value={128}](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1705 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1706 : int = prim::Constant[value=3](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:66:0
  %1707 : int = prim::Constant[value=2](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:66:0
  %1708 : bool = prim::Constant[value=1](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %1709 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %1710 : int = prim::Constant[value=245760](), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %1711 : NoneType = prim::Constant(), scope: __module.to_patch_embedding
  %1712 : str = prim::Constant[value="constant"](), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1713 : int = prim::Constant[value=0](), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1714 : int = prim::Constant[value=-1](), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1715 : int = prim::Constant[value=1](), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %to_patch_tokens : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="to_patch_tokens"](%to_patch_embedding)
  %1717 : int[] = prim::ListConstruct(%1715, %1714, %1713, %1713), scope: __module.to_patch_embedding
  %1718 : Float(128, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=0, device=cuda:0) = aten::pad(%img, %1717, %1712, %1711), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1719 : int[] = prim::ListConstruct(%1714, %1715, %1713, %1713), scope: __module.to_patch_embedding
  %1720 : Float(128, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=0, device=cuda:0) = aten::pad(%img, %1719, %1712, %1711), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1721 : int[] = prim::ListConstruct(%1713, %1713, %1715, %1714), scope: __module.to_patch_embedding
  %1722 : Float(128, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=0, device=cuda:0) = aten::pad(%img, %1721, %1712, %1711), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1723 : int[] = prim::ListConstruct(%1713, %1713, %1714, %1715), scope: __module.to_patch_embedding
  %1724 : Float(128, 3, 256, 256, strides=[196608, 65536, 256, 1], requires_grad=0, device=cuda:0) = aten::pad(%img, %1723, %1712, %1711), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:94:0
  %1725 : Tensor[] = prim::ListConstruct(%img, %1718, %1720, %1722, %1724), scope: __module.to_patch_embedding
  %x.1 : Float(128, 15, 256, 256, strides=[983040, 65536, 256, 1], requires_grad=0, device=cuda:0) = aten::cat(%1725, %1715), scope: __module.to_patch_embedding # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:95:0
  %_2.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="2"](%to_patch_tokens)
  %_1.1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="1"](%to_patch_tokens)
  %_0.1 : __torch__.einops.layers.torch.Rearrange = prim::GetAttr[name="0"](%to_patch_tokens)
  %1730 : int = aten::size(%x.1, %1713), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:66:0
  %1731 : Long(device=cpu) = prim::NumToTensor(%1730), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %1732 : int = aten::size(%x.1, %1715), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:66:0
  %1733 : Long(device=cpu) = prim::NumToTensor(%1732), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %1734 : int = aten::size(%x.1, %1707), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:66:0
  %1735 : Long(device=cpu) = prim::NumToTensor(%1734), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %1736 : int = aten::size(%x.1, %1706), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:66:0
  %1737 : Long(device=cpu) = prim::NumToTensor(%1736), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %element.1 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1731, %1705), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1739 : int = aten::Int(%element.1), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %element.7 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1733, %1705), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1741 : int = aten::Int(%element.7), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %element.3 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1735, %1704), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1743 : int = aten::Int(%element.3), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %element.5 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1737, %1704), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1745 : int = aten::Int(%element.5), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %1746 : Long(requires_grad=0, device=cpu) = aten::mul(%element.1, %1705), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1747 : int = aten::Int(%1746), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %result.1 : Long(requires_grad=0, device=cpu) = aten::mul(%element.3, %1705), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1749 : Long(requires_grad=0, device=cpu) = aten::mul_(%result.1, %element.5), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1750 : int = aten::Int(%1749), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %1751 : Long(requires_grad=0, device=cpu) = aten::mul(%element.7, %1703), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1752 : int = aten::Int(%1751), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %1753 : int[] = prim::ListConstruct(%1739, %1741, %1743, %1702, %1745, %1702), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %x.3 : Float(128, 15, 2, 128, 2, 128, strides=[983040, 65536, 32768, 256, 128, 1], requires_grad=0, device=cuda:0) = aten::reshape(%x.1, %1753), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:70:0
  %1755 : int[] = prim::ListConstruct(%1713, %1707, %1701, %1706, %1700, %1715), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %x.5 : Float(128, 2, 2, 128, 128, 15, strides=[983040, 32768, 128, 256, 1, 65536], requires_grad=0, device=cuda:0) = aten::permute(%x.3, %1755), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:42:0
  %1757 : int[] = prim::ListConstruct(%1747, %1750, %1752), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0
  %input.1 : Float(128, 4, 245760, strides=[983040, 245760, 1], requires_grad=0, device=cuda:0) = aten::reshape(%x.5, %1757), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_torch_specific.py:70:0
  %bias.21 : Tensor = prim::GetAttr[name="bias"](%_1.1)
  %weight.21 : Tensor = prim::GetAttr[name="weight"](%_1.1)
  %1761 : int[] = prim::ListConstruct(%1710), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.1
  %input.3 : Float(128, 4, 245760, strides=[983040, 245760, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.1, %1761, %weight.21, %bias.21, %1709, %1708), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %bias.23 : Tensor = prim::GetAttr[name="bias"](%_2.1)
  %weight.23 : Tensor = prim::GetAttr[name="weight"](%_2.1)
  %x.7 : Float(128, 4, 512, strides=[2048, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.3, %weight.23, %bias.23), scope: __module.to_patch_embedding/__module.to_patch_embedding.to_patch_tokens/__module.to_patch_embedding.to_patch_tokens.2 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %391 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:128:0
  %392 : int = aten::size(%x.7, %391) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:128:0
  %element.9 : Long(device=cpu) = prim::NumToTensor(%392)
  %429 : int = aten::Int(%element.9)
  %394 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:128:0
  %395 : int = aten::size(%x.7, %394) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:128:0
  %n : Long(device=cpu) = prim::NumToTensor(%395)
  %403 : int = prim::Constant[value=1]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %404 : int = aten::size(%cls_token, %403) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %405 : Long(device=cpu) = prim::NumToTensor(%404)
  %406 : int = prim::Constant[value=2]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %407 : int = aten::size(%cls_token, %406) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %408 : Long(device=cpu) = prim::NumToTensor(%407)
  %409 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %element.11 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%405, %409) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %419 : int = aten::Int(%element.11)
  %411 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %element.13 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%408, %411) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %420 : int = aten::Int(%element.13)
  %413 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %414 : Long(requires_grad=0, device=cpu) = aten::mul(%element.9, %413) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %435 : int = aten::Int(%414)
  %415 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %416 : Long(requires_grad=0, device=cpu) = aten::mul(%element.11, %415) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %436 : int = aten::Int(%416)
  %417 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %418 : Long(requires_grad=0, device=cpu) = aten::mul(%element.13, %417) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %437 : int = aten::Int(%418)
  %421 : int[] = prim::ListConstruct(%419, %420)
  %x.11 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cuda:0) = aten::reshape(%cls_token, %421) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %423 : int = prim::Constant[value=0]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %424 : int = prim::Constant[value=1]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %425 : int[] = prim::ListConstruct(%423, %424)
  %x.13 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.11, %425) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %427 : int = prim::Constant[value=0]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:310:0
  %x.15 : Float(1, 1, 512, strides=[512, 512, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%x.13, %427) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:310:0
  %430 : int = prim::Constant[value=-1]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:301:0
  %431 : int = prim::Constant[value=-1]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:301:0
  %432 : int[] = prim::ListConstruct(%429, %430, %431)
  %433 : bool = prim::Constant[value=0]() # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:301:0
  %x.17 : Float(128, 1, 512, strides=[0, 512, 1], requires_grad=1, device=cuda:0) = aten::expand(%x.15, %432, %433) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:301:0
  %438 : int[] = prim::ListConstruct(%435, %436, %437)
  %cls_tokens : Float(128, 1, 512, strides=[0, 512, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.17, %438) # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %440 : Tensor[] = prim::ListConstruct(%cls_tokens, %x.7)
  %441 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:131:0
  %x.19 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::cat(%440, %441) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:131:0
  %443 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %444 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %445 : Long(requires_grad=0, device=cpu) = aten::add(%n, %443, %444) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %451 : int = aten::Int(%445)
  %446 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %447 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %448 : int = prim::Constant[value=9223372036854775807]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %449 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %450 : Float(1, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::slice(%pos_embedding, %446, %447, %448, %449) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %452 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %453 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %454 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %455 : Float(1, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::slice(%450, %452, %453, %451, %454) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %456 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %input.5 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add_(%x.19, %455, %456) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:132:0
  %1766 : bool = prim::Constant[value=0](), scope: __module.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %1767 : float = prim::Constant[value=0.29999999999999999](), scope: __module.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.7 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.5, %1767, %1766), scope: __module.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %1769 : str = prim::Constant[value="none"](), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.2 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/activation.py:685:0
  %1770 : bool = prim::Constant[value=1](), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %1771 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %1772 : int = prim::Constant[value=512](), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %1773 : NoneType = prim::Constant(), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.to_qkv
  %1774 : int = prim::Constant[value=3](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:50:0
  %1775 : int = prim::Constant[value=-1](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:50:0
  %1776 : int = prim::Constant[value=0](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1777 : int = prim::Constant[value=1](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1778 : int = prim::Constant[value=2](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1779 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1780 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1781 : int = prim::Constant[value=4](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1782 : int = prim::Constant[value=-2](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %1783 : int = prim::Constant[value=11](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %1784 : Device = prim::Constant[value="cuda:0"](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %1785 : bool = prim::Constant[value=0](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %1786 : float = prim::Constant[value=-3.4028234663852886e+38](), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:57:0
  %1787 : float = prim::Constant[value=0.29999999999999999](), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %layers : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_3 : __torch__.torch.nn.modules.container.___torch_mangle_62.ModuleList = prim::GetAttr[name="3"](%layers)
  %_1.29 : __torch__.vit_pytorch.vit_for_small_dataset.___torch_mangle_61.FeedForward = prim::GetAttr[name="1"](%_3)
  %layers.13 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_3.7 : __torch__.torch.nn.modules.container.___torch_mangle_62.ModuleList = prim::GetAttr[name="3"](%layers.13)
  %_0.27 : __torch__.vit_pytorch.vit_for_small_dataset.___torch_mangle_53.LSA = prim::GetAttr[name="0"](%_3.7)
  %layers.11 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_2.11 : __torch__.torch.nn.modules.container.___torch_mangle_45.ModuleList = prim::GetAttr[name="2"](%layers.11)
  %_1.23 : __torch__.vit_pytorch.vit_for_small_dataset.___torch_mangle_44.FeedForward = prim::GetAttr[name="1"](%_2.11)
  %layers.9 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_2.7 : __torch__.torch.nn.modules.container.___torch_mangle_45.ModuleList = prim::GetAttr[name="2"](%layers.9)
  %_0.21 : __torch__.vit_pytorch.vit_for_small_dataset.___torch_mangle_36.LSA = prim::GetAttr[name="0"](%_2.7)
  %layers.7 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_1.15 : __torch__.torch.nn.modules.container.___torch_mangle_28.ModuleList = prim::GetAttr[name="1"](%layers.7)
  %_1.17 : __torch__.vit_pytorch.vit_for_small_dataset.___torch_mangle_27.FeedForward = prim::GetAttr[name="1"](%_1.15)
  %layers.5 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_1.11 : __torch__.torch.nn.modules.container.___torch_mangle_28.ModuleList = prim::GetAttr[name="1"](%layers.5)
  %_0.15 : __torch__.vit_pytorch.vit_for_small_dataset.___torch_mangle_19.LSA = prim::GetAttr[name="0"](%_1.11)
  %layers.3 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_0.11 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="0"](%layers.3)
  %_1.7 : __torch__.vit_pytorch.vit_for_small_dataset.FeedForward = prim::GetAttr[name="1"](%_0.11)
  %layers.1 : __torch__.torch.nn.modules.container.___torch_mangle_63.ModuleList = prim::GetAttr[name="layers"](%transformer)
  %_0.5 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="0"](%layers.1)
  %_0.7 : __torch__.vit_pytorch.vit_for_small_dataset.LSA = prim::GetAttr[name="0"](%_0.5)
  %to_out.1 : __torch__.torch.nn.modules.container.___torch_mangle_5.Sequential = prim::GetAttr[name="to_out"](%_0.7)
  %temperature.1 : Tensor = prim::GetAttr[name="temperature"](%_0.7)
  %to_qkv.1 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name="to_qkv"](%_0.7)
  %norm.1 : __torch__.torch.nn.modules.normalization.___torch_mangle_0.LayerNorm = prim::GetAttr[name="norm"](%_0.7)
  %bias.25 : Tensor = prim::GetAttr[name="bias"](%norm.1)
  %weight.25 : Tensor = prim::GetAttr[name="weight"](%norm.1)
  %1818 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.norm
  %input.9 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.7, %1818, %weight.25, %bias.25, %1771, %1770), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %weight.27 : Tensor = prim::GetAttr[name="weight"](%to_qkv.1)
  %1821 : Float(128, 5, 768, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.9, %weight.27, %1773), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.to_qkv # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %1822 : Tensor[] = aten::chunk(%1821, %1774, %1775), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:50:0
  %x.21 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.27 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.33 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = prim::ListUnpack(%1822), scope: __module.transformer/__module.transformer.layers.0.0
  %1826 : int = aten::size(%x.21, %1776), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1827 : Long(device=cpu) = prim::NumToTensor(%1826), scope: __module.transformer/__module.transformer.layers.0.0
  %1828 : int = aten::size(%x.21, %1777), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1829 : Long(device=cpu) = prim::NumToTensor(%1828), scope: __module.transformer/__module.transformer.layers.0.0
  %1830 : int = aten::size(%x.21, %1778), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1831 : Long(device=cpu) = prim::NumToTensor(%1830), scope: __module.transformer/__module.transformer.layers.0.0
  %element.15 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1827, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1833 : int = aten::Int(%element.15), scope: __module.transformer/__module.transformer.layers.0.0
  %element.17 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1829, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1835 : int = aten::Int(%element.17), scope: __module.transformer/__module.transformer.layers.0.0
  %element.19 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1831, %1780), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1837 : int = aten::Int(%element.19), scope: __module.transformer/__module.transformer.layers.0.0
  %1838 : Long(requires_grad=0, device=cpu) = aten::mul(%element.15, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1839 : int = aten::Int(%1838), scope: __module.transformer/__module.transformer.layers.0.0
  %1840 : Long(requires_grad=0, device=cpu) = aten::mul(%element.17, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1841 : int = aten::Int(%1840), scope: __module.transformer/__module.transformer.layers.0.0
  %1842 : Long(requires_grad=0, device=cpu) = aten::mul(%element.19, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1843 : int = aten::Int(%1842), scope: __module.transformer/__module.transformer.layers.0.0
  %1844 : int[] = prim::ListConstruct(%1833, %1835, %1781, %1837), scope: __module.transformer/__module.transformer.layers.0.0
  %x.23 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.21, %1844), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1846 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.0.0
  %x.25 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.23, %1846), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %1848 : int[] = prim::ListConstruct(%1839, %1781, %1841, %1843), scope: __module.transformer/__module.transformer.layers.0.0
  %q.1 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.25, %1848), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1850 : int = aten::size(%x.27, %1776), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1851 : Long(device=cpu) = prim::NumToTensor(%1850), scope: __module.transformer/__module.transformer.layers.0.0
  %1852 : int = aten::size(%x.27, %1777), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1853 : Long(device=cpu) = prim::NumToTensor(%1852), scope: __module.transformer/__module.transformer.layers.0.0
  %1854 : int = aten::size(%x.27, %1778), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1855 : Long(device=cpu) = prim::NumToTensor(%1854), scope: __module.transformer/__module.transformer.layers.0.0
  %element.21 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1851, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1857 : int = aten::Int(%element.21), scope: __module.transformer/__module.transformer.layers.0.0
  %element.23 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1853, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1859 : int = aten::Int(%element.23), scope: __module.transformer/__module.transformer.layers.0.0
  %element.25 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1855, %1780), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1861 : int = aten::Int(%element.25), scope: __module.transformer/__module.transformer.layers.0.0
  %1862 : Long(requires_grad=0, device=cpu) = aten::mul(%element.21, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1863 : int = aten::Int(%1862), scope: __module.transformer/__module.transformer.layers.0.0
  %1864 : Long(requires_grad=0, device=cpu) = aten::mul(%element.23, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1865 : int = aten::Int(%1864), scope: __module.transformer/__module.transformer.layers.0.0
  %1866 : Long(requires_grad=0, device=cpu) = aten::mul(%element.25, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1867 : int = aten::Int(%1866), scope: __module.transformer/__module.transformer.layers.0.0
  %1868 : int[] = prim::ListConstruct(%1857, %1859, %1781, %1861), scope: __module.transformer/__module.transformer.layers.0.0
  %x.29 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.27, %1868), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1870 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.0.0
  %x.31 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.29, %1870), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %1872 : int[] = prim::ListConstruct(%1863, %1781, %1865, %1867), scope: __module.transformer/__module.transformer.layers.0.0
  %k.1 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.31, %1872), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1874 : int = aten::size(%x.33, %1776), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1875 : Long(device=cpu) = prim::NumToTensor(%1874), scope: __module.transformer/__module.transformer.layers.0.0
  %1876 : int = aten::size(%x.33, %1777), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1877 : Long(device=cpu) = prim::NumToTensor(%1876), scope: __module.transformer/__module.transformer.layers.0.0
  %1878 : int = aten::size(%x.33, %1778), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1879 : Long(device=cpu) = prim::NumToTensor(%1878), scope: __module.transformer/__module.transformer.layers.0.0
  %element.27 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1875, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1881 : int = aten::Int(%element.27), scope: __module.transformer/__module.transformer.layers.0.0
  %element.29 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1877, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1883 : int = aten::Int(%element.29), scope: __module.transformer/__module.transformer.layers.0.0
  %element.31 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1879, %1780), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1885 : int = aten::Int(%element.31), scope: __module.transformer/__module.transformer.layers.0.0
  %1886 : Long(requires_grad=0, device=cpu) = aten::mul(%element.27, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1887 : int = aten::Int(%1886), scope: __module.transformer/__module.transformer.layers.0.0
  %1888 : Long(requires_grad=0, device=cpu) = aten::mul(%element.29, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1889 : int = aten::Int(%1888), scope: __module.transformer/__module.transformer.layers.0.0
  %1890 : Long(requires_grad=0, device=cpu) = aten::mul(%element.31, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1891 : int = aten::Int(%1890), scope: __module.transformer/__module.transformer.layers.0.0
  %1892 : int[] = prim::ListConstruct(%1881, %1883, %1781, %1885), scope: __module.transformer/__module.transformer.layers.0.0
  %x.35 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.33, %1892), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1894 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.0.0
  %x.37 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.35, %1894), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %1896 : int[] = prim::ListConstruct(%1887, %1781, %1889, %1891), scope: __module.transformer/__module.transformer.layers.0.0
  %v.1 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.37, %1896), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1898 : Float(128, 4, 64, 5, strides=[3840, 64, 1, 768], requires_grad=1, device=cuda:0) = aten::transpose(%k.1, %1775, %1782), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %1899 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::matmul(%q.1, %1898), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %1900 : Float(requires_grad=1, device=cuda:0) = aten::exp(%temperature.1), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %dots.1 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::mul(%1899, %1900), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %1902 : int = aten::size(%dots.1, %1774), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %mask.1 : Bool(5, 5, strides=[5, 1], requires_grad=0, device=cuda:0) = aten::eye(%1902, %1783, %1773, %1784, %1785), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %input.11 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::masked_fill(%dots.1, %mask.1, %1786), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:57:0
  %input.13 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::softmax(%input.11, %1775, %1773), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.attend # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1843:0
  %attn.1 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.13, %1787, %1785), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %x.39 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::matmul(%attn.1, %v.1), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:62:0
  %1908 : int = aten::size(%x.39, %1776), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1909 : Long(device=cpu) = prim::NumToTensor(%1908), scope: __module.transformer/__module.transformer.layers.0.0
  %1910 : int = aten::size(%x.39, %1777), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1911 : Long(device=cpu) = prim::NumToTensor(%1910), scope: __module.transformer/__module.transformer.layers.0.0
  %1912 : int = aten::size(%x.39, %1778), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1913 : Long(device=cpu) = prim::NumToTensor(%1912), scope: __module.transformer/__module.transformer.layers.0.0
  %1914 : int = aten::size(%x.39, %1774), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1915 : Long(device=cpu) = prim::NumToTensor(%1914), scope: __module.transformer/__module.transformer.layers.0.0
  %element.33 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1909, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1917 : int = aten::Int(%element.33), scope: __module.transformer/__module.transformer.layers.0.0
  %element.37 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1911, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1919 : int = aten::Int(%element.37), scope: __module.transformer/__module.transformer.layers.0.0
  %element.35 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1913, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1921 : int = aten::Int(%element.35), scope: __module.transformer/__module.transformer.layers.0.0
  %element.39 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1915, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1923 : int = aten::Int(%element.39), scope: __module.transformer/__module.transformer.layers.0.0
  %1924 : Long(requires_grad=0, device=cpu) = aten::mul(%element.33, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1925 : int = aten::Int(%1924), scope: __module.transformer/__module.transformer.layers.0.0
  %1926 : Long(requires_grad=0, device=cpu) = aten::mul(%element.35, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1927 : int = aten::Int(%1926), scope: __module.transformer/__module.transformer.layers.0.0
  %result.3 : Long(requires_grad=0, device=cpu) = aten::mul(%element.37, %1779), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1929 : Long(requires_grad=0, device=cpu) = aten::mul_(%result.3, %element.39), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1930 : int = aten::Int(%1929), scope: __module.transformer/__module.transformer.layers.0.0
  %1931 : int[] = prim::ListConstruct(%1917, %1919, %1921, %1923), scope: __module.transformer/__module.transformer.layers.0.0
  %x.41 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.39, %1931), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1933 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.0.0
  %x.43 : Float(128, 5, 4, 64, strides=[1280, 64, 320, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.41, %1933), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %1935 : int[] = prim::ListConstruct(%1925, %1927, %1930), scope: __module.transformer/__module.transformer.layers.0.0
  %input.15 : Float(128, 5, 256, strides=[1280, 256, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.43, %1935), scope: __module.transformer/__module.transformer.layers.0.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %_0.3 : __torch__.torch.nn.modules.linear.___torch_mangle_3.Linear = prim::GetAttr[name="0"](%to_out.1)
  %bias.27 : Tensor = prim::GetAttr[name="bias"](%_0.3)
  %weight.29 : Tensor = prim::GetAttr[name="weight"](%_0.3)
  %input.17 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.15, %weight.29, %bias.27), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.to_out/__module.transformer.layers.0.0.to_out.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %1941 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.17, %1787, %1785), scope: __module.transformer/__module.transformer.layers.0.0/__module.transformer.layers.0.0.to_out/__module.transformer.layers.0.0.to_out.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.19 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%1941, %input.7, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:77:0
  %net.1 : __torch__.torch.nn.modules.container.___torch_mangle_11.Sequential = prim::GetAttr[name="net"](%_1.7)
  %_5.1 : __torch__.torch.nn.modules.dropout.___torch_mangle_10.Dropout = prim::GetAttr[name="5"](%net.1)
  %_4.1 : __torch__.torch.nn.modules.linear.___torch_mangle_9.Linear = prim::GetAttr[name="4"](%net.1)
  %_3.1 : __torch__.torch.nn.modules.dropout.___torch_mangle_8.Dropout = prim::GetAttr[name="3"](%net.1)
  %_2.3 : __torch__.torch.nn.modules.activation.GELU = prim::GetAttr[name="2"](%net.1)
  %_1.5 : __torch__.torch.nn.modules.linear.___torch_mangle_7.Linear = prim::GetAttr[name="1"](%net.1)
  %_0.9 : __torch__.torch.nn.modules.normalization.___torch_mangle_6.LayerNorm = prim::GetAttr[name="0"](%net.1)
  %bias.29 : Tensor = prim::GetAttr[name="bias"](%_0.9)
  %weight.31 : Tensor = prim::GetAttr[name="weight"](%_0.9)
  %1952 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.0
  %input.21 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.19, %1952, %weight.31, %bias.29, %1771, %1770), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %bias.31 : Tensor = prim::GetAttr[name="bias"](%_1.5)
  %weight.33 : Tensor = prim::GetAttr[name="weight"](%_1.5)
  %input.23 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.21, %weight.33, %bias.31), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %input.25 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::gelu(%input.23, %1769), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.2 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/activation.py:685:0
  %input.27 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.25, %1787, %1785), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.3 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %bias.33 : Tensor = prim::GetAttr[name="bias"](%_4.1)
  %weight.35 : Tensor = prim::GetAttr[name="weight"](%_4.1)
  %input.29 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.27, %weight.35, %bias.33), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.4 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %1962 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.29, %1787, %1785), scope: __module.transformer/__module.transformer.layers.0.1/__module.transformer.layers.0.1.net/__module.transformer.layers.0.1.net.5 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.31 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%1962, %input.19, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:78:0
  %to_out.3 : __torch__.torch.nn.modules.container.___torch_mangle_18.Sequential = prim::GetAttr[name="to_out"](%_0.15)
  %temperature.3 : Tensor = prim::GetAttr[name="temperature"](%_0.15)
  %to_qkv.3 : __torch__.torch.nn.modules.linear.___torch_mangle_15.Linear = prim::GetAttr[name="to_qkv"](%_0.15)
  %norm.3 : __torch__.torch.nn.modules.normalization.___torch_mangle_12.LayerNorm = prim::GetAttr[name="norm"](%_0.15)
  %bias.35 : Tensor = prim::GetAttr[name="bias"](%norm.3)
  %weight.37 : Tensor = prim::GetAttr[name="weight"](%norm.3)
  %1970 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.norm
  %input.33 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.31, %1970, %weight.37, %bias.35, %1771, %1770), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %weight.39 : Tensor = prim::GetAttr[name="weight"](%to_qkv.3)
  %1973 : Float(128, 5, 768, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.33, %weight.39, %1773), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.to_qkv # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %1974 : Tensor[] = aten::chunk(%1973, %1774, %1775), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:50:0
  %x.45 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.51 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.57 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = prim::ListUnpack(%1974), scope: __module.transformer/__module.transformer.layers.1.0
  %1978 : int = aten::size(%x.45, %1776), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1979 : Long(device=cpu) = prim::NumToTensor(%1978), scope: __module.transformer/__module.transformer.layers.1.0
  %1980 : int = aten::size(%x.45, %1777), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1981 : Long(device=cpu) = prim::NumToTensor(%1980), scope: __module.transformer/__module.transformer.layers.1.0
  %1982 : int = aten::size(%x.45, %1778), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %1983 : Long(device=cpu) = prim::NumToTensor(%1982), scope: __module.transformer/__module.transformer.layers.1.0
  %element.41 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1979, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1985 : int = aten::Int(%element.41), scope: __module.transformer/__module.transformer.layers.1.0
  %element.43 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1981, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1987 : int = aten::Int(%element.43), scope: __module.transformer/__module.transformer.layers.1.0
  %element.45 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1983, %1780), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %1989 : int = aten::Int(%element.45), scope: __module.transformer/__module.transformer.layers.1.0
  %1990 : Long(requires_grad=0, device=cpu) = aten::mul(%element.41, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1991 : int = aten::Int(%1990), scope: __module.transformer/__module.transformer.layers.1.0
  %1992 : Long(requires_grad=0, device=cpu) = aten::mul(%element.43, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1993 : int = aten::Int(%1992), scope: __module.transformer/__module.transformer.layers.1.0
  %1994 : Long(requires_grad=0, device=cpu) = aten::mul(%element.45, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %1995 : int = aten::Int(%1994), scope: __module.transformer/__module.transformer.layers.1.0
  %1996 : int[] = prim::ListConstruct(%1985, %1987, %1781, %1989), scope: __module.transformer/__module.transformer.layers.1.0
  %x.47 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.45, %1996), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %1998 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.1.0
  %x.49 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.47, %1998), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2000 : int[] = prim::ListConstruct(%1991, %1781, %1993, %1995), scope: __module.transformer/__module.transformer.layers.1.0
  %q.3 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.49, %2000), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2002 : int = aten::size(%x.51, %1776), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2003 : Long(device=cpu) = prim::NumToTensor(%2002), scope: __module.transformer/__module.transformer.layers.1.0
  %2004 : int = aten::size(%x.51, %1777), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2005 : Long(device=cpu) = prim::NumToTensor(%2004), scope: __module.transformer/__module.transformer.layers.1.0
  %2006 : int = aten::size(%x.51, %1778), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2007 : Long(device=cpu) = prim::NumToTensor(%2006), scope: __module.transformer/__module.transformer.layers.1.0
  %element.47 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2003, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2009 : int = aten::Int(%element.47), scope: __module.transformer/__module.transformer.layers.1.0
  %element.49 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2005, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2011 : int = aten::Int(%element.49), scope: __module.transformer/__module.transformer.layers.1.0
  %element.51 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2007, %1780), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2013 : int = aten::Int(%element.51), scope: __module.transformer/__module.transformer.layers.1.0
  %2014 : Long(requires_grad=0, device=cpu) = aten::mul(%element.47, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2015 : int = aten::Int(%2014), scope: __module.transformer/__module.transformer.layers.1.0
  %2016 : Long(requires_grad=0, device=cpu) = aten::mul(%element.49, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2017 : int = aten::Int(%2016), scope: __module.transformer/__module.transformer.layers.1.0
  %2018 : Long(requires_grad=0, device=cpu) = aten::mul(%element.51, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2019 : int = aten::Int(%2018), scope: __module.transformer/__module.transformer.layers.1.0
  %2020 : int[] = prim::ListConstruct(%2009, %2011, %1781, %2013), scope: __module.transformer/__module.transformer.layers.1.0
  %x.53 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.51, %2020), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2022 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.1.0
  %x.55 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.53, %2022), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2024 : int[] = prim::ListConstruct(%2015, %1781, %2017, %2019), scope: __module.transformer/__module.transformer.layers.1.0
  %k.3 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.55, %2024), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2026 : int = aten::size(%x.57, %1776), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2027 : Long(device=cpu) = prim::NumToTensor(%2026), scope: __module.transformer/__module.transformer.layers.1.0
  %2028 : int = aten::size(%x.57, %1777), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2029 : Long(device=cpu) = prim::NumToTensor(%2028), scope: __module.transformer/__module.transformer.layers.1.0
  %2030 : int = aten::size(%x.57, %1778), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2031 : Long(device=cpu) = prim::NumToTensor(%2030), scope: __module.transformer/__module.transformer.layers.1.0
  %element.53 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2027, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2033 : int = aten::Int(%element.53), scope: __module.transformer/__module.transformer.layers.1.0
  %element.55 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2029, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2035 : int = aten::Int(%element.55), scope: __module.transformer/__module.transformer.layers.1.0
  %element.57 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2031, %1780), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2037 : int = aten::Int(%element.57), scope: __module.transformer/__module.transformer.layers.1.0
  %2038 : Long(requires_grad=0, device=cpu) = aten::mul(%element.53, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2039 : int = aten::Int(%2038), scope: __module.transformer/__module.transformer.layers.1.0
  %2040 : Long(requires_grad=0, device=cpu) = aten::mul(%element.55, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2041 : int = aten::Int(%2040), scope: __module.transformer/__module.transformer.layers.1.0
  %2042 : Long(requires_grad=0, device=cpu) = aten::mul(%element.57, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2043 : int = aten::Int(%2042), scope: __module.transformer/__module.transformer.layers.1.0
  %2044 : int[] = prim::ListConstruct(%2033, %2035, %1781, %2037), scope: __module.transformer/__module.transformer.layers.1.0
  %x.59 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.57, %2044), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2046 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.1.0
  %x.61 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.59, %2046), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2048 : int[] = prim::ListConstruct(%2039, %1781, %2041, %2043), scope: __module.transformer/__module.transformer.layers.1.0
  %v.3 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.61, %2048), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2050 : Float(128, 4, 64, 5, strides=[3840, 64, 1, 768], requires_grad=1, device=cuda:0) = aten::transpose(%k.3, %1775, %1782), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2051 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::matmul(%q.3, %2050), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2052 : Float(requires_grad=1, device=cuda:0) = aten::exp(%temperature.3), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %dots.3 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::mul(%2051, %2052), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2054 : int = aten::size(%dots.3, %1774), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %mask.3 : Bool(5, 5, strides=[5, 1], requires_grad=0, device=cuda:0) = aten::eye(%2054, %1783, %1773, %1784, %1785), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %input.35 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::masked_fill(%dots.3, %mask.3, %1786), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:57:0
  %input.37 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::softmax(%input.35, %1775, %1773), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.attend # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1843:0
  %attn.3 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.37, %1787, %1785), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %x.63 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::matmul(%attn.3, %v.3), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:62:0
  %2060 : int = aten::size(%x.63, %1776), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2061 : Long(device=cpu) = prim::NumToTensor(%2060), scope: __module.transformer/__module.transformer.layers.1.0
  %2062 : int = aten::size(%x.63, %1777), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2063 : Long(device=cpu) = prim::NumToTensor(%2062), scope: __module.transformer/__module.transformer.layers.1.0
  %2064 : int = aten::size(%x.63, %1778), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2065 : Long(device=cpu) = prim::NumToTensor(%2064), scope: __module.transformer/__module.transformer.layers.1.0
  %2066 : int = aten::size(%x.63, %1774), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2067 : Long(device=cpu) = prim::NumToTensor(%2066), scope: __module.transformer/__module.transformer.layers.1.0
  %element.59 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2061, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2069 : int = aten::Int(%element.59), scope: __module.transformer/__module.transformer.layers.1.0
  %element.63 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2063, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2071 : int = aten::Int(%element.63), scope: __module.transformer/__module.transformer.layers.1.0
  %element.61 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2065, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2073 : int = aten::Int(%element.61), scope: __module.transformer/__module.transformer.layers.1.0
  %element.65 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2067, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2075 : int = aten::Int(%element.65), scope: __module.transformer/__module.transformer.layers.1.0
  %2076 : Long(requires_grad=0, device=cpu) = aten::mul(%element.59, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2077 : int = aten::Int(%2076), scope: __module.transformer/__module.transformer.layers.1.0
  %2078 : Long(requires_grad=0, device=cpu) = aten::mul(%element.61, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2079 : int = aten::Int(%2078), scope: __module.transformer/__module.transformer.layers.1.0
  %result.5 : Long(requires_grad=0, device=cpu) = aten::mul(%element.63, %1779), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2081 : Long(requires_grad=0, device=cpu) = aten::mul_(%result.5, %element.65), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2082 : int = aten::Int(%2081), scope: __module.transformer/__module.transformer.layers.1.0
  %2083 : int[] = prim::ListConstruct(%2069, %2071, %2073, %2075), scope: __module.transformer/__module.transformer.layers.1.0
  %x.65 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.63, %2083), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2085 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.1.0
  %x.67 : Float(128, 5, 4, 64, strides=[1280, 64, 320, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.65, %2085), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2087 : int[] = prim::ListConstruct(%2077, %2079, %2082), scope: __module.transformer/__module.transformer.layers.1.0
  %input.39 : Float(128, 5, 256, strides=[1280, 256, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.67, %2087), scope: __module.transformer/__module.transformer.layers.1.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %_0.13 : __torch__.torch.nn.modules.linear.___torch_mangle_16.Linear = prim::GetAttr[name="0"](%to_out.3)
  %bias.37 : Tensor = prim::GetAttr[name="bias"](%_0.13)
  %weight.41 : Tensor = prim::GetAttr[name="weight"](%_0.13)
  %input.41 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.39, %weight.41, %bias.37), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.to_out/__module.transformer.layers.1.0.to_out.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2093 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.41, %1787, %1785), scope: __module.transformer/__module.transformer.layers.1.0/__module.transformer.layers.1.0.to_out/__module.transformer.layers.1.0.to_out.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.43 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%2093, %input.31, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:77:0
  %net.3 : __torch__.torch.nn.modules.container.___torch_mangle_26.Sequential = prim::GetAttr[name="net"](%_1.17)
  %_5.3 : __torch__.torch.nn.modules.dropout.___torch_mangle_25.Dropout = prim::GetAttr[name="5"](%net.3)
  %_4.3 : __torch__.torch.nn.modules.linear.___torch_mangle_24.Linear = prim::GetAttr[name="4"](%net.3)
  %_3.3 : __torch__.torch.nn.modules.dropout.___torch_mangle_23.Dropout = prim::GetAttr[name="3"](%net.3)
  %_2.5 : __torch__.torch.nn.modules.activation.___torch_mangle_22.GELU = prim::GetAttr[name="2"](%net.3)
  %_1.13 : __torch__.torch.nn.modules.linear.___torch_mangle_21.Linear = prim::GetAttr[name="1"](%net.3)
  %_0.17 : __torch__.torch.nn.modules.normalization.___torch_mangle_20.LayerNorm = prim::GetAttr[name="0"](%net.3)
  %bias.39 : Tensor = prim::GetAttr[name="bias"](%_0.17)
  %weight.43 : Tensor = prim::GetAttr[name="weight"](%_0.17)
  %2104 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.0
  %input.45 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.43, %2104, %weight.43, %bias.39, %1771, %1770), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %bias.41 : Tensor = prim::GetAttr[name="bias"](%_1.13)
  %weight.45 : Tensor = prim::GetAttr[name="weight"](%_1.13)
  %input.47 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.45, %weight.45, %bias.41), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %input.49 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::gelu(%input.47, %1769), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.2 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/activation.py:685:0
  %input.51 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.49, %1787, %1785), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.3 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %bias.43 : Tensor = prim::GetAttr[name="bias"](%_4.3)
  %weight.47 : Tensor = prim::GetAttr[name="weight"](%_4.3)
  %input.53 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.51, %weight.47, %bias.43), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.4 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2114 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.53, %1787, %1785), scope: __module.transformer/__module.transformer.layers.1.1/__module.transformer.layers.1.1.net/__module.transformer.layers.1.1.net.5 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.55 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%2114, %input.43, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:78:0
  %to_out.5 : __torch__.torch.nn.modules.container.___torch_mangle_35.Sequential = prim::GetAttr[name="to_out"](%_0.21)
  %temperature.5 : Tensor = prim::GetAttr[name="temperature"](%_0.21)
  %to_qkv.5 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name="to_qkv"](%_0.21)
  %norm.5 : __torch__.torch.nn.modules.normalization.___torch_mangle_29.LayerNorm = prim::GetAttr[name="norm"](%_0.21)
  %bias.45 : Tensor = prim::GetAttr[name="bias"](%norm.5)
  %weight.49 : Tensor = prim::GetAttr[name="weight"](%norm.5)
  %2122 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.norm
  %input.57 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.55, %2122, %weight.49, %bias.45, %1771, %1770), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %weight.51 : Tensor = prim::GetAttr[name="weight"](%to_qkv.5)
  %2125 : Float(128, 5, 768, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.57, %weight.51, %1773), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.to_qkv # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2126 : Tensor[] = aten::chunk(%2125, %1774, %1775), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:50:0
  %x.69 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.75 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.81 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = prim::ListUnpack(%2126), scope: __module.transformer/__module.transformer.layers.2.0
  %2130 : int = aten::size(%x.69, %1776), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2131 : Long(device=cpu) = prim::NumToTensor(%2130), scope: __module.transformer/__module.transformer.layers.2.0
  %2132 : int = aten::size(%x.69, %1777), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2133 : Long(device=cpu) = prim::NumToTensor(%2132), scope: __module.transformer/__module.transformer.layers.2.0
  %2134 : int = aten::size(%x.69, %1778), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2135 : Long(device=cpu) = prim::NumToTensor(%2134), scope: __module.transformer/__module.transformer.layers.2.0
  %element.67 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2131, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2137 : int = aten::Int(%element.67), scope: __module.transformer/__module.transformer.layers.2.0
  %element.69 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2133, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2139 : int = aten::Int(%element.69), scope: __module.transformer/__module.transformer.layers.2.0
  %element.71 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2135, %1780), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2141 : int = aten::Int(%element.71), scope: __module.transformer/__module.transformer.layers.2.0
  %2142 : Long(requires_grad=0, device=cpu) = aten::mul(%element.67, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2143 : int = aten::Int(%2142), scope: __module.transformer/__module.transformer.layers.2.0
  %2144 : Long(requires_grad=0, device=cpu) = aten::mul(%element.69, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2145 : int = aten::Int(%2144), scope: __module.transformer/__module.transformer.layers.2.0
  %2146 : Long(requires_grad=0, device=cpu) = aten::mul(%element.71, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2147 : int = aten::Int(%2146), scope: __module.transformer/__module.transformer.layers.2.0
  %2148 : int[] = prim::ListConstruct(%2137, %2139, %1781, %2141), scope: __module.transformer/__module.transformer.layers.2.0
  %x.71 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.69, %2148), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2150 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.2.0
  %x.73 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.71, %2150), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2152 : int[] = prim::ListConstruct(%2143, %1781, %2145, %2147), scope: __module.transformer/__module.transformer.layers.2.0
  %q.5 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.73, %2152), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2154 : int = aten::size(%x.75, %1776), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2155 : Long(device=cpu) = prim::NumToTensor(%2154), scope: __module.transformer/__module.transformer.layers.2.0
  %2156 : int = aten::size(%x.75, %1777), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2157 : Long(device=cpu) = prim::NumToTensor(%2156), scope: __module.transformer/__module.transformer.layers.2.0
  %2158 : int = aten::size(%x.75, %1778), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2159 : Long(device=cpu) = prim::NumToTensor(%2158), scope: __module.transformer/__module.transformer.layers.2.0
  %element.73 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2155, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2161 : int = aten::Int(%element.73), scope: __module.transformer/__module.transformer.layers.2.0
  %element.75 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2157, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2163 : int = aten::Int(%element.75), scope: __module.transformer/__module.transformer.layers.2.0
  %element.77 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2159, %1780), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2165 : int = aten::Int(%element.77), scope: __module.transformer/__module.transformer.layers.2.0
  %2166 : Long(requires_grad=0, device=cpu) = aten::mul(%element.73, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2167 : int = aten::Int(%2166), scope: __module.transformer/__module.transformer.layers.2.0
  %2168 : Long(requires_grad=0, device=cpu) = aten::mul(%element.75, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2169 : int = aten::Int(%2168), scope: __module.transformer/__module.transformer.layers.2.0
  %2170 : Long(requires_grad=0, device=cpu) = aten::mul(%element.77, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2171 : int = aten::Int(%2170), scope: __module.transformer/__module.transformer.layers.2.0
  %2172 : int[] = prim::ListConstruct(%2161, %2163, %1781, %2165), scope: __module.transformer/__module.transformer.layers.2.0
  %x.77 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.75, %2172), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2174 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.2.0
  %x.79 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.77, %2174), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2176 : int[] = prim::ListConstruct(%2167, %1781, %2169, %2171), scope: __module.transformer/__module.transformer.layers.2.0
  %k.5 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.79, %2176), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2178 : int = aten::size(%x.81, %1776), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2179 : Long(device=cpu) = prim::NumToTensor(%2178), scope: __module.transformer/__module.transformer.layers.2.0
  %2180 : int = aten::size(%x.81, %1777), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2181 : Long(device=cpu) = prim::NumToTensor(%2180), scope: __module.transformer/__module.transformer.layers.2.0
  %2182 : int = aten::size(%x.81, %1778), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2183 : Long(device=cpu) = prim::NumToTensor(%2182), scope: __module.transformer/__module.transformer.layers.2.0
  %element.79 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2179, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2185 : int = aten::Int(%element.79), scope: __module.transformer/__module.transformer.layers.2.0
  %element.81 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2181, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2187 : int = aten::Int(%element.81), scope: __module.transformer/__module.transformer.layers.2.0
  %element.83 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2183, %1780), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2189 : int = aten::Int(%element.83), scope: __module.transformer/__module.transformer.layers.2.0
  %2190 : Long(requires_grad=0, device=cpu) = aten::mul(%element.79, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2191 : int = aten::Int(%2190), scope: __module.transformer/__module.transformer.layers.2.0
  %2192 : Long(requires_grad=0, device=cpu) = aten::mul(%element.81, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2193 : int = aten::Int(%2192), scope: __module.transformer/__module.transformer.layers.2.0
  %2194 : Long(requires_grad=0, device=cpu) = aten::mul(%element.83, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2195 : int = aten::Int(%2194), scope: __module.transformer/__module.transformer.layers.2.0
  %2196 : int[] = prim::ListConstruct(%2185, %2187, %1781, %2189), scope: __module.transformer/__module.transformer.layers.2.0
  %x.83 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.81, %2196), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2198 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.2.0
  %x.85 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.83, %2198), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2200 : int[] = prim::ListConstruct(%2191, %1781, %2193, %2195), scope: __module.transformer/__module.transformer.layers.2.0
  %v.5 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.85, %2200), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2202 : Float(128, 4, 64, 5, strides=[3840, 64, 1, 768], requires_grad=1, device=cuda:0) = aten::transpose(%k.5, %1775, %1782), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2203 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::matmul(%q.5, %2202), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2204 : Float(requires_grad=1, device=cuda:0) = aten::exp(%temperature.5), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %dots.5 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::mul(%2203, %2204), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2206 : int = aten::size(%dots.5, %1774), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %mask.5 : Bool(5, 5, strides=[5, 1], requires_grad=0, device=cuda:0) = aten::eye(%2206, %1783, %1773, %1784, %1785), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %input.59 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::masked_fill(%dots.5, %mask.5, %1786), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:57:0
  %input.61 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::softmax(%input.59, %1775, %1773), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.attend # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1843:0
  %attn.5 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.61, %1787, %1785), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %x.87 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::matmul(%attn.5, %v.5), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:62:0
  %2212 : int = aten::size(%x.87, %1776), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2213 : Long(device=cpu) = prim::NumToTensor(%2212), scope: __module.transformer/__module.transformer.layers.2.0
  %2214 : int = aten::size(%x.87, %1777), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2215 : Long(device=cpu) = prim::NumToTensor(%2214), scope: __module.transformer/__module.transformer.layers.2.0
  %2216 : int = aten::size(%x.87, %1778), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2217 : Long(device=cpu) = prim::NumToTensor(%2216), scope: __module.transformer/__module.transformer.layers.2.0
  %2218 : int = aten::size(%x.87, %1774), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2219 : Long(device=cpu) = prim::NumToTensor(%2218), scope: __module.transformer/__module.transformer.layers.2.0
  %element.85 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2213, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2221 : int = aten::Int(%element.85), scope: __module.transformer/__module.transformer.layers.2.0
  %element.89 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2215, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2223 : int = aten::Int(%element.89), scope: __module.transformer/__module.transformer.layers.2.0
  %element.87 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2217, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2225 : int = aten::Int(%element.87), scope: __module.transformer/__module.transformer.layers.2.0
  %element.91 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2219, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2227 : int = aten::Int(%element.91), scope: __module.transformer/__module.transformer.layers.2.0
  %2228 : Long(requires_grad=0, device=cpu) = aten::mul(%element.85, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2229 : int = aten::Int(%2228), scope: __module.transformer/__module.transformer.layers.2.0
  %2230 : Long(requires_grad=0, device=cpu) = aten::mul(%element.87, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2231 : int = aten::Int(%2230), scope: __module.transformer/__module.transformer.layers.2.0
  %result.7 : Long(requires_grad=0, device=cpu) = aten::mul(%element.89, %1779), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2233 : Long(requires_grad=0, device=cpu) = aten::mul_(%result.7, %element.91), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2234 : int = aten::Int(%2233), scope: __module.transformer/__module.transformer.layers.2.0
  %2235 : int[] = prim::ListConstruct(%2221, %2223, %2225, %2227), scope: __module.transformer/__module.transformer.layers.2.0
  %x.89 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.87, %2235), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2237 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.2.0
  %x.91 : Float(128, 5, 4, 64, strides=[1280, 64, 320, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.89, %2237), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2239 : int[] = prim::ListConstruct(%2229, %2231, %2234), scope: __module.transformer/__module.transformer.layers.2.0
  %input.63 : Float(128, 5, 256, strides=[1280, 256, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.91, %2239), scope: __module.transformer/__module.transformer.layers.2.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %_0.19 : __torch__.torch.nn.modules.linear.___torch_mangle_33.Linear = prim::GetAttr[name="0"](%to_out.5)
  %bias.47 : Tensor = prim::GetAttr[name="bias"](%_0.19)
  %weight.53 : Tensor = prim::GetAttr[name="weight"](%_0.19)
  %input.65 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.63, %weight.53, %bias.47), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.to_out/__module.transformer.layers.2.0.to_out.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2245 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.65, %1787, %1785), scope: __module.transformer/__module.transformer.layers.2.0/__module.transformer.layers.2.0.to_out/__module.transformer.layers.2.0.to_out.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.67 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%2245, %input.55, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:77:0
  %net.5 : __torch__.torch.nn.modules.container.___torch_mangle_43.Sequential = prim::GetAttr[name="net"](%_1.23)
  %_5.5 : __torch__.torch.nn.modules.dropout.___torch_mangle_42.Dropout = prim::GetAttr[name="5"](%net.5)
  %_4.5 : __torch__.torch.nn.modules.linear.___torch_mangle_41.Linear = prim::GetAttr[name="4"](%net.5)
  %_3.5 : __torch__.torch.nn.modules.dropout.___torch_mangle_40.Dropout = prim::GetAttr[name="3"](%net.5)
  %_2.9 : __torch__.torch.nn.modules.activation.___torch_mangle_39.GELU = prim::GetAttr[name="2"](%net.5)
  %_1.21 : __torch__.torch.nn.modules.linear.___torch_mangle_38.Linear = prim::GetAttr[name="1"](%net.5)
  %_0.23 : __torch__.torch.nn.modules.normalization.___torch_mangle_37.LayerNorm = prim::GetAttr[name="0"](%net.5)
  %bias.49 : Tensor = prim::GetAttr[name="bias"](%_0.23)
  %weight.55 : Tensor = prim::GetAttr[name="weight"](%_0.23)
  %2256 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.0
  %input.69 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.67, %2256, %weight.55, %bias.49, %1771, %1770), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %bias.51 : Tensor = prim::GetAttr[name="bias"](%_1.21)
  %weight.57 : Tensor = prim::GetAttr[name="weight"](%_1.21)
  %input.71 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.69, %weight.57, %bias.51), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %input.73 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::gelu(%input.71, %1769), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.2 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/activation.py:685:0
  %input.75 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.73, %1787, %1785), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.3 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %bias.53 : Tensor = prim::GetAttr[name="bias"](%_4.5)
  %weight.59 : Tensor = prim::GetAttr[name="weight"](%_4.5)
  %input.77 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.75, %weight.59, %bias.53), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.4 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2266 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.77, %1787, %1785), scope: __module.transformer/__module.transformer.layers.2.1/__module.transformer.layers.2.1.net/__module.transformer.layers.2.1.net.5 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.79 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%2266, %input.67, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:78:0
  %to_out : __torch__.torch.nn.modules.container.___torch_mangle_52.Sequential = prim::GetAttr[name="to_out"](%_0.27)
  %temperature : Tensor = prim::GetAttr[name="temperature"](%_0.27)
  %to_qkv : __torch__.torch.nn.modules.linear.___torch_mangle_49.Linear = prim::GetAttr[name="to_qkv"](%_0.27)
  %norm : __torch__.torch.nn.modules.normalization.___torch_mangle_46.LayerNorm = prim::GetAttr[name="norm"](%_0.27)
  %bias.55 : Tensor = prim::GetAttr[name="bias"](%norm)
  %weight.61 : Tensor = prim::GetAttr[name="weight"](%norm)
  %2274 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.norm
  %input.81 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.79, %2274, %weight.61, %bias.55, %1771, %1770), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.norm # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %weight.63 : Tensor = prim::GetAttr[name="weight"](%to_qkv)
  %2277 : Float(128, 5, 768, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.81, %weight.63, %1773), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.to_qkv # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2278 : Tensor[] = aten::chunk(%2277, %1774, %1775), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:50:0
  %x.93 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.99 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0), %x.105 : Float(128, 5, 256, strides=[3840, 768, 1], requires_grad=1, device=cuda:0) = prim::ListUnpack(%2278), scope: __module.transformer/__module.transformer.layers.3.0
  %2282 : int = aten::size(%x.93, %1776), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2283 : Long(device=cpu) = prim::NumToTensor(%2282), scope: __module.transformer/__module.transformer.layers.3.0
  %2284 : int = aten::size(%x.93, %1777), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2285 : Long(device=cpu) = prim::NumToTensor(%2284), scope: __module.transformer/__module.transformer.layers.3.0
  %2286 : int = aten::size(%x.93, %1778), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2287 : Long(device=cpu) = prim::NumToTensor(%2286), scope: __module.transformer/__module.transformer.layers.3.0
  %element.93 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2283, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2289 : int = aten::Int(%element.93), scope: __module.transformer/__module.transformer.layers.3.0
  %element.95 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2285, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2291 : int = aten::Int(%element.95), scope: __module.transformer/__module.transformer.layers.3.0
  %element.97 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2287, %1780), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2293 : int = aten::Int(%element.97), scope: __module.transformer/__module.transformer.layers.3.0
  %2294 : Long(requires_grad=0, device=cpu) = aten::mul(%element.93, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2295 : int = aten::Int(%2294), scope: __module.transformer/__module.transformer.layers.3.0
  %2296 : Long(requires_grad=0, device=cpu) = aten::mul(%element.95, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2297 : int = aten::Int(%2296), scope: __module.transformer/__module.transformer.layers.3.0
  %2298 : Long(requires_grad=0, device=cpu) = aten::mul(%element.97, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2299 : int = aten::Int(%2298), scope: __module.transformer/__module.transformer.layers.3.0
  %2300 : int[] = prim::ListConstruct(%2289, %2291, %1781, %2293), scope: __module.transformer/__module.transformer.layers.3.0
  %x.95 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.93, %2300), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2302 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.3.0
  %x.97 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.95, %2302), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2304 : int[] = prim::ListConstruct(%2295, %1781, %2297, %2299), scope: __module.transformer/__module.transformer.layers.3.0
  %q : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.97, %2304), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2306 : int = aten::size(%x.99, %1776), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2307 : Long(device=cpu) = prim::NumToTensor(%2306), scope: __module.transformer/__module.transformer.layers.3.0
  %2308 : int = aten::size(%x.99, %1777), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2309 : Long(device=cpu) = prim::NumToTensor(%2308), scope: __module.transformer/__module.transformer.layers.3.0
  %2310 : int = aten::size(%x.99, %1778), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2311 : Long(device=cpu) = prim::NumToTensor(%2310), scope: __module.transformer/__module.transformer.layers.3.0
  %element.99 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2307, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2313 : int = aten::Int(%element.99), scope: __module.transformer/__module.transformer.layers.3.0
  %element.101 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2309, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2315 : int = aten::Int(%element.101), scope: __module.transformer/__module.transformer.layers.3.0
  %element.103 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2311, %1780), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2317 : int = aten::Int(%element.103), scope: __module.transformer/__module.transformer.layers.3.0
  %2318 : Long(requires_grad=0, device=cpu) = aten::mul(%element.99, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2319 : int = aten::Int(%2318), scope: __module.transformer/__module.transformer.layers.3.0
  %2320 : Long(requires_grad=0, device=cpu) = aten::mul(%element.101, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2321 : int = aten::Int(%2320), scope: __module.transformer/__module.transformer.layers.3.0
  %2322 : Long(requires_grad=0, device=cpu) = aten::mul(%element.103, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2323 : int = aten::Int(%2322), scope: __module.transformer/__module.transformer.layers.3.0
  %2324 : int[] = prim::ListConstruct(%2313, %2315, %1781, %2317), scope: __module.transformer/__module.transformer.layers.3.0
  %x.101 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.99, %2324), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2326 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.3.0
  %x.103 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.101, %2326), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2328 : int[] = prim::ListConstruct(%2319, %1781, %2321, %2323), scope: __module.transformer/__module.transformer.layers.3.0
  %k : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.103, %2328), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2330 : int = aten::size(%x.105, %1776), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2331 : Long(device=cpu) = prim::NumToTensor(%2330), scope: __module.transformer/__module.transformer.layers.3.0
  %2332 : int = aten::size(%x.105, %1777), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2333 : Long(device=cpu) = prim::NumToTensor(%2332), scope: __module.transformer/__module.transformer.layers.3.0
  %2334 : int = aten::size(%x.105, %1778), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2335 : Long(device=cpu) = prim::NumToTensor(%2334), scope: __module.transformer/__module.transformer.layers.3.0
  %element.105 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2331, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2337 : int = aten::Int(%element.105), scope: __module.transformer/__module.transformer.layers.3.0
  %element.107 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2333, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2339 : int = aten::Int(%element.107), scope: __module.transformer/__module.transformer.layers.3.0
  %element.109 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2335, %1780), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2341 : int = aten::Int(%element.109), scope: __module.transformer/__module.transformer.layers.3.0
  %2342 : Long(requires_grad=0, device=cpu) = aten::mul(%element.105, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2343 : int = aten::Int(%2342), scope: __module.transformer/__module.transformer.layers.3.0
  %2344 : Long(requires_grad=0, device=cpu) = aten::mul(%element.107, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2345 : int = aten::Int(%2344), scope: __module.transformer/__module.transformer.layers.3.0
  %2346 : Long(requires_grad=0, device=cpu) = aten::mul(%element.109, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2347 : int = aten::Int(%2346), scope: __module.transformer/__module.transformer.layers.3.0
  %2348 : int[] = prim::ListConstruct(%2337, %2339, %1781, %2341), scope: __module.transformer/__module.transformer.layers.3.0
  %x.107 : Float(128, 5, 4, 64, strides=[3840, 768, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.105, %2348), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2350 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.3.0
  %x.109 : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.107, %2350), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2352 : int[] = prim::ListConstruct(%2343, %1781, %2345, %2347), scope: __module.transformer/__module.transformer.layers.3.0
  %v : Float(128, 4, 5, 64, strides=[3840, 64, 768, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.109, %2352), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2354 : Float(128, 4, 64, 5, strides=[3840, 64, 1, 768], requires_grad=1, device=cuda:0) = aten::transpose(%k, %1775, %1782), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2355 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::matmul(%q, %2354), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2356 : Float(requires_grad=1, device=cuda:0) = aten::exp(%temperature), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %dots : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::mul(%2355, %2356), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:53:0
  %2358 : int = aten::size(%dots, %1774), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %mask : Bool(5, 5, strides=[5, 1], requires_grad=0, device=cuda:0) = aten::eye(%2358, %1783, %1773, %1784, %1785), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:55:0
  %input.83 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::masked_fill(%dots, %mask, %1786), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:57:0
  %input.85 : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::softmax(%input.83, %1775, %1773), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.attend # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1843:0
  %attn : Float(128, 4, 5, 5, strides=[100, 25, 5, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.85, %1787, %1785), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.dropout # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %x.111 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::matmul(%attn, %v), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:62:0
  %2364 : int = aten::size(%x.111, %1776), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2365 : Long(device=cpu) = prim::NumToTensor(%2364), scope: __module.transformer/__module.transformer.layers.3.0
  %2366 : int = aten::size(%x.111, %1777), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2367 : Long(device=cpu) = prim::NumToTensor(%2366), scope: __module.transformer/__module.transformer.layers.3.0
  %2368 : int = aten::size(%x.111, %1778), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2369 : Long(device=cpu) = prim::NumToTensor(%2368), scope: __module.transformer/__module.transformer.layers.3.0
  %2370 : int = aten::size(%x.111, %1774), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:81:0
  %2371 : Long(device=cpu) = prim::NumToTensor(%2370), scope: __module.transformer/__module.transformer.layers.3.0
  %element.111 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2365, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2373 : int = aten::Int(%element.111), scope: __module.transformer/__module.transformer.layers.3.0
  %element.115 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2367, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2375 : int = aten::Int(%element.115), scope: __module.transformer/__module.transformer.layers.3.0
  %element.113 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2369, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2377 : int = aten::Int(%element.113), scope: __module.transformer/__module.transformer.layers.3.0
  %element : Long(requires_grad=0, device=cpu) = aten::floor_divide(%2371, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/_tensor.py:882:0
  %2379 : int = aten::Int(%element), scope: __module.transformer/__module.transformer.layers.3.0
  %2380 : Long(requires_grad=0, device=cpu) = aten::mul(%element.111, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2381 : int = aten::Int(%2380), scope: __module.transformer/__module.transformer.layers.3.0
  %2382 : Long(requires_grad=0, device=cpu) = aten::mul(%element.113, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2383 : int = aten::Int(%2382), scope: __module.transformer/__module.transformer.layers.3.0
  %result : Long(requires_grad=0, device=cpu) = aten::mul(%element.115, %1779), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2385 : Long(requires_grad=0, device=cpu) = aten::mul_(%result, %element), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/einops.py:36:0
  %2386 : int = aten::Int(%2385), scope: __module.transformer/__module.transformer.layers.3.0
  %2387 : int[] = prim::ListConstruct(%2373, %2375, %2377, %2379), scope: __module.transformer/__module.transformer.layers.3.0
  %x.113 : Float(128, 4, 5, 64, strides=[1280, 320, 64, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.111, %2387), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %2389 : int[] = prim::ListConstruct(%1776, %1778, %1777, %1774), scope: __module.transformer/__module.transformer.layers.3.0
  %x.115 : Float(128, 5, 4, 64, strides=[1280, 64, 320, 1], requires_grad=1, device=cuda:0) = aten::permute(%x.113, %2389), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:291:0
  %2391 : int[] = prim::ListConstruct(%2381, %2383, %2386), scope: __module.transformer/__module.transformer.layers.3.0
  %input.87 : Float(128, 5, 256, strides=[1280, 256, 1], requires_grad=1, device=cuda:0) = aten::reshape(%x.115, %2391), scope: __module.transformer/__module.transformer.layers.3.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/einops/_backends.py:84:0
  %_0.25 : __torch__.torch.nn.modules.linear.___torch_mangle_50.Linear = prim::GetAttr[name="0"](%to_out)
  %bias.57 : Tensor = prim::GetAttr[name="bias"](%_0.25)
  %weight.65 : Tensor = prim::GetAttr[name="weight"](%_0.25)
  %input.89 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.87, %weight.65, %bias.57), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.to_out/__module.transformer.layers.3.0.to_out.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2397 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.89, %1787, %1785), scope: __module.transformer/__module.transformer.layers.3.0/__module.transformer.layers.3.0.to_out/__module.transformer.layers.3.0.to_out.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %input.91 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%2397, %input.79, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:77:0
  %net : __torch__.torch.nn.modules.container.___torch_mangle_60.Sequential = prim::GetAttr[name="net"](%_1.29)
  %_5 : __torch__.torch.nn.modules.dropout.___torch_mangle_59.Dropout = prim::GetAttr[name="5"](%net)
  %_4 : __torch__.torch.nn.modules.linear.___torch_mangle_58.Linear = prim::GetAttr[name="4"](%net)
  %_3.9 : __torch__.torch.nn.modules.dropout.___torch_mangle_57.Dropout = prim::GetAttr[name="3"](%net)
  %_2 : __torch__.torch.nn.modules.activation.___torch_mangle_56.GELU = prim::GetAttr[name="2"](%net)
  %_1.27 : __torch__.torch.nn.modules.linear.___torch_mangle_55.Linear = prim::GetAttr[name="1"](%net)
  %_0.29 : __torch__.torch.nn.modules.normalization.___torch_mangle_54.LayerNorm = prim::GetAttr[name="0"](%net)
  %bias.59 : Tensor = prim::GetAttr[name="bias"](%_0.29)
  %weight.67 : Tensor = prim::GetAttr[name="weight"](%_0.29)
  %2408 : int[] = prim::ListConstruct(%1772), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.0
  %input.93 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.91, %2408, %weight.67, %bias.59, %1771, %1770), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %bias.61 : Tensor = prim::GetAttr[name="bias"](%_1.27)
  %weight.69 : Tensor = prim::GetAttr[name="weight"](%_1.27)
  %input.95 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.93, %weight.69, %bias.61), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %input.97 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::gelu(%input.95, %1769), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.2 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/activation.py:685:0
  %input.99 : Float(128, 5, 1024, strides=[5120, 1024, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.97, %1787, %1785), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.3 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %bias.63 : Tensor = prim::GetAttr[name="bias"](%_4)
  %weight.71 : Tensor = prim::GetAttr[name="weight"](%_4)
  %input.101 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::linear(%input.99, %weight.71, %bias.63), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.4 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  %2418 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::dropout(%input.101, %1787, %1785), scope: __module.transformer/__module.transformer.layers.3.1/__module.transformer.layers.3.1.net/__module.transformer.layers.3.1.net.5 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:1252:0
  %x : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::add(%2418, %input.91, %1777), scope: __module.transformer # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:78:0
  %1381 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %1382 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %1383 : int = prim::Constant[value=9223372036854775807]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %1384 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %1385 : Float(128, 5, 512, strides=[2560, 512, 1], requires_grad=1, device=cuda:0) = aten::slice(%x, %1381, %1382, %1383, %1384) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %1386 : int = prim::Constant[value=1]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %1387 : int = prim::Constant[value=0]() # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %input.103 : Float(128, 512, strides=[2560, 1], requires_grad=1, device=cuda:0) = aten::select(%1385, %1386, %1387) # /home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/vit_pytorch/vit_for_small_dataset.py:137:0
  %2420 : NoneType = prim::Constant()
  %2421 : int = prim::Constant[value=512](), scope: __module.mlp_head/__module.mlp_head.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %2422 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.mlp_head/__module.mlp_head.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %2423 : bool = prim::Constant[value=1](), scope: __module.mlp_head/__module.mlp_head.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %_1 : __torch__.torch.nn.modules.linear.___torch_mangle_65.Linear = prim::GetAttr[name="1"](%mlp_head)
  %_0 : __torch__.torch.nn.modules.normalization.___torch_mangle_64.LayerNorm = prim::GetAttr[name="0"](%mlp_head)
  %bias.65 : Tensor = prim::GetAttr[name="bias"](%_0)
  %weight.73 : Tensor = prim::GetAttr[name="weight"](%_0)
  %2428 : int[] = prim::ListConstruct(%2421), scope: __module.mlp_head/__module.mlp_head.0
  %input : Float(128, 512, strides=[512, 1], requires_grad=1, device=cuda:0) = aten::layer_norm(%input.103, %2428, %weight.73, %bias.65, %2422, %2423), scope: __module.mlp_head/__module.mlp_head.0 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/functional.py:2515:0
  %bias : Tensor = prim::GetAttr[name="bias"](%_1)
  %weight : Tensor = prim::GetAttr[name="weight"](%_1)
  %2432 : Float(128, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = aten::linear(%input, %weight, %bias), scope: __module.mlp_head/__module.mlp_head.1 # /home/Student/s4737925/miniconda3/envs/new_base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0
  return (%2432)

 [>................................................................]  Step: 2s901ms | Tot: 0ms | Loss: 0.732 | Acc: 46.094% (59/128) 1/169  [>................................................................]  Step: 314ms | Tot: 314ms | Loss: 0.824 | Acc: 50.781% (130/256) 2/169  [>................................................................]  Step: 267ms | Tot: 582ms | Loss: 0.877 | Acc: 49.740% (191/384) 3/169  [=>...............................................................]  Step: 287ms | Tot: 869ms | Loss: 0.835 | Acc: 50.781% (260/512) 4/169  [=>...............................................................]  Step: 272ms | Tot: 1s141ms | Loss: 0.811 | Acc: 51.094% (327/640) 5/169  [=>...............................................................]  Step: 271ms | Tot: 1s413ms | Loss: 0.815 | Acc: 50.781% (390/768) 6/169  [==>..............................................................]  Step: 270ms | Tot: 1s683ms | Loss: 0.803 | Acc: 51.228% (459/896) 7/169  [==>..............................................................]  Step: 271ms | Tot: 1s955ms | Loss: 0.790 | Acc: 51.758% (530/1024) 8/169  [===>.............................................................]  Step: 273ms | Tot: 2s228ms | Loss: 0.786 | Acc: 51.649% (595/1152) 9/169  [===>.............................................................]  Step: 267ms | Tot: 2s496ms | Loss: 0.779 | Acc: 51.250% (656/1280) 10/169  [===>.............................................................]  Step: 274ms | Tot: 2s771ms | Loss: 0.772 | Acc: 51.776% (729/1408) 11/169  [====>............................................................]  Step: 272ms | Tot: 3s43ms | Loss: 0.767 | Acc: 51.758% (795/1536) 12/169  [====>............................................................]  Step: 272ms | Tot: 3s315ms | Loss: 0.768 | Acc: 51.502% (857/1664) 13/169  [=====>...........................................................]  Step: 315ms | Tot: 3s631ms | Loss: 0.763 | Acc: 52.009% (932/1792) 14/169  [=====>...........................................................]  Step: 282ms | Tot: 3s914ms | Loss: 0.759 | Acc: 51.771% (994/1920) 15/169  [=====>...........................................................]  Step: 269ms | Tot: 4s183ms | Loss: 0.755 | Acc: 51.611% (1057/2048) 16/169  [======>..........................................................]  Step: 272ms | Tot: 4s455ms | Loss: 0.752 | Acc: 51.700% (1125/2176) 17/169  [======>..........................................................]  Step: 271ms | Tot: 4s726ms | Loss: 0.749 | Acc: 51.649% (1190/2304) 18/169  [======>..........................................................]  Step: 273ms | Tot: 5s | Loss: 0.748 | Acc: 51.645% (1256/2432) 19/169  [=======>.........................................................]  Step: 269ms | Tot: 5s269ms | Loss: 0.746 | Acc: 51.680% (1323/2560) 20/169  [=======>.........................................................]  Step: 273ms | Tot: 5s542ms | Loss: 0.745 | Acc: 51.637% (1388/2688) 21/169  [========>........................................................]  Step: 286ms | Tot: 5s829ms | Loss: 0.743 | Acc: 51.953% (1463/2816) 22/169  [========>........................................................]  Step: 269ms | Tot: 6s98ms | Loss: 0.742 | Acc: 51.868% (1527/2944) 23/169  [========>........................................................]  Step: 271ms | Tot: 6s370ms | Loss: 0.739 | Acc: 51.855% (1593/3072) 24/169  [=========>.......................................................]  Step: 268ms | Tot: 6s639ms | Loss: 0.737 | Acc: 51.938% (1662/3200) 25/169  [=========>.......................................................]  Step: 297ms | Tot: 6s936ms | Loss: 0.736 | Acc: 51.923% (1728/3328) 26/169  [==========>......................................................]  Step: 273ms | Tot: 7s209ms | Loss: 0.734 | Acc: 52.083% (1800/3456) 27/169  [==========>......................................................]  Step: 272ms | Tot: 7s482ms | Loss: 0.733 | Acc: 51.953% (1862/3584) 28/169  [==========>......................................................]  Step: 274ms | Tot: 7s757ms | Loss: 0.731 | Acc: 52.101% (1934/3712) 29/169  [===========>.....................................................]  Step: 277ms | Tot: 8s34ms | Loss: 0.730 | Acc: 52.161% (2003/3840) 30/169  [===========>.....................................................]  Step: 273ms | Tot: 8s307ms | Loss: 0.729 | Acc: 52.319% (2076/3968) 31/169  [===========>.....................................................]  Step: 274ms | Tot: 8s581ms | Loss: 0.728 | Acc: 52.222% (2139/4096) 32/169  [============>....................................................]  Step: 303ms | Tot: 8s885ms | Loss: 0.726 | Acc: 52.367% (2212/4224) 33/169  [============>....................................................]  Step: 274ms | Tot: 9s159ms | Loss: 0.726 | Acc: 52.252% (2274/4352) 34/169  [=============>...................................................]  Step: 271ms | Tot: 9s431ms | Loss: 0.726 | Acc: 52.054% (2332/4480) 35/169  [=============>...................................................]  Step: 275ms | Tot: 9s706ms | Loss: 0.725 | Acc: 52.083% (2400/4608) 36/169  [=============>...................................................]  Step: 272ms | Tot: 9s979ms | Loss: 0.724 | Acc: 52.196% (2472/4736) 37/169  [==============>..................................................]  Step: 307ms | Tot: 10s287ms | Loss: 0.724 | Acc: 52.241% (2541/4864) 38/169  [==============>..................................................]  Step: 275ms | Tot: 10s562ms | Loss: 0.724 | Acc: 52.143% (2603/4992) 39/169  [===============>.................................................]  Step: 285ms | Tot: 10s848ms | Loss: 0.724 | Acc: 52.090% (2667/5120) 40/169  [===============>.................................................]  Step: 272ms | Tot: 11s120ms | Loss: 0.723 | Acc: 51.982% (2728/5248) 41/169  [===============>.................................................]  Step: 274ms | Tot: 11s394ms | Loss: 0.723 | Acc: 52.028% (2797/5376) 42/169  [================>................................................]  Step: 273ms | Tot: 11s668ms | Loss: 0.723 | Acc: 52.035% (2864/5504) 43/169  [================>................................................]  Step: 275ms | Tot: 11s943ms | Loss: 0.723 | Acc: 52.095% (2934/5632) 44/169  [================>................................................]  Step: 269ms | Tot: 12s213ms | Loss: 0.722 | Acc: 52.118% (3002/5760) 45/169  [=================>...............................................]  Step: 274ms | Tot: 12s487ms | Loss: 0.721 | Acc: 52.276% (3078/5888) 46/169  [=================>...............................................]  Step: 271ms | Tot: 12s758ms | Loss: 0.721 | Acc: 52.327% (3148/6016) 47/169  [==================>..............................................]  Step: 276ms | Tot: 13s35ms | Loss: 0.720 | Acc: 52.279% (3212/6144) 48/169  [==================>..............................................]  Step: 274ms | Tot: 13s309ms | Loss: 0.720 | Acc: 52.216% (3275/6272) 49/169  [==================>..............................................]  Step: 311ms | Tot: 13s621ms | Loss: 0.719 | Acc: 52.203% (3341/6400) 50/169  [===================>.............................................]  Step: 284ms | Tot: 13s906ms | Loss: 0.719 | Acc: 52.206% (3408/6528) 51/169  [===================>.............................................]  Step: 269ms | Tot: 14s176ms | Loss: 0.718 | Acc: 52.329% (3483/6656) 52/169  [====================>............................................]  Step: 271ms | Tot: 14s447ms | Loss: 0.718 | Acc: 52.344% (3551/6784) 53/169  [====================>............................................]  Step: 272ms | Tot: 14s720ms | Loss: 0.717 | Acc: 52.445% (3625/6912) 54/169  [====================>............................................]  Step: 273ms | Tot: 14s993ms | Loss: 0.717 | Acc: 52.429% (3691/7040) 55/169  [=====================>...........................................]  Step: 272ms | Tot: 15s266ms | Loss: 0.717 | Acc: 52.414% (3757/7168) 56/169  [=====================>...........................................]  Step: 276ms | Tot: 15s543ms | Loss: 0.716 | Acc: 52.495% (3830/7296) 57/169  [=====================>...........................................]  Step: 287ms | Tot: 15s830ms | Loss: 0.715 | Acc: 52.640% (3908/7424) 58/169  [======================>..........................................]  Step: 272ms | Tot: 16s103ms | Loss: 0.715 | Acc: 52.675% (3978/7552) 59/169  [======================>..........................................]  Step: 271ms | Tot: 16s375ms | Loss: 0.714 | Acc: 52.878% (4061/7680) 60/169  [=======================>.........................................]  Step: 271ms | Tot: 16s646ms | Loss: 0.714 | Acc: 52.779% (4121/7808) 61/169  [=======================>.........................................]  Step: 282ms | Tot: 16s929ms | Loss: 0.714 | Acc: 52.860% (4195/7936) 62/169  [=======================>.........................................]  Step: 272ms | Tot: 17s202ms | Loss: 0.713 | Acc: 52.951% (4270/8064) 63/169  [========================>........................................]  Step: 273ms | Tot: 17s475ms | Loss: 0.713 | Acc: 52.844% (4329/8192) 64/169  [========================>........................................]  Step: 313ms | Tot: 17s788ms | Loss: 0.713 | Acc: 52.825% (4395/8320) 65/169  [=========================>.......................................]  Step: 273ms | Tot: 18s62ms | Loss: 0.713 | Acc: 52.900% (4469/8448) 66/169  [=========================>.......................................]  Step: 273ms | Tot: 18s336ms | Loss: 0.712 | Acc: 52.962% (4542/8576) 67/169  [=========================>.......................................]  Step: 276ms | Tot: 18s612ms | Loss: 0.712 | Acc: 53.045% (4617/8704) 68/169  [==========================>......................................]  Step: 297ms | Tot: 18s909ms | Loss: 0.711 | Acc: 53.204% (4699/8832) 69/169  [==========================>......................................]  Step: 274ms | Tot: 19s184ms | Loss: 0.711 | Acc: 53.114% (4759/8960) 70/169  [==========================>......................................]  Step: 273ms | Tot: 19s457ms | Loss: 0.711 | Acc: 53.026% (4819/9088) 71/169  [===========================>.....................................]  Step: 440ms | Tot: 19s898ms | Loss: 0.710 | Acc: 53.136% (4897/9216) 72/169  [===========================>.....................................]  Step: 275ms | Tot: 20s173ms | Loss: 0.710 | Acc: 53.221% (4973/9344) 73/169  [============================>....................................]  Step: 272ms | Tot: 20s446ms | Loss: 0.710 | Acc: 53.231% (5042/9472) 74/169  [============================>....................................]  Step: 289ms | Tot: 20s736ms | Loss: 0.710 | Acc: 53.271% (5114/9600) 75/169  [============================>....................................]  Step: 272ms | Tot: 21s9ms | Loss: 0.710 | Acc: 53.300% (5185/9728) 76/169  [=============================>...................................]  Step: 273ms | Tot: 21s282ms | Loss: 0.710 | Acc: 53.267% (5250/9856) 77/169  [=============================>...................................]  Step: 274ms | Tot: 21s556ms | Loss: 0.709 | Acc: 53.415% (5333/9984) 78/169  [==============================>..................................]  Step: 274ms | Tot: 21s831ms | Loss: 0.709 | Acc: 53.570% (5417/10112) 79/169  [==============================>..................................]  Step: 272ms | Tot: 22s104ms | Loss: 0.708 | Acc: 53.564% (5485/10240) 80/169  [==============================>..................................]  Step: 275ms | Tot: 22s379ms | Loss: 0.708 | Acc: 53.578% (5555/10368) 81/169  [===============================>.................................]  Step: 272ms | Tot: 22s651ms | Loss: 0.708 | Acc: 53.611% (5627/10496) 82/169  [===============================>.................................]  Step: 275ms | Tot: 22s927ms | Loss: 0.708 | Acc: 53.662% (5701/10624) 83/169  [===============================>.................................]  Step: 276ms | Tot: 23s204ms | Loss: 0.708 | Acc: 53.674% (5771/10752) 84/169  [================================>................................]  Step: 272ms | Tot: 23s476ms | Loss: 0.708 | Acc: 53.695% (5842/10880) 85/169  [================================>................................]  Step: 272ms | Tot: 23s748ms | Loss: 0.707 | Acc: 53.734% (5915/11008) 86/169  [=================================>...............................]  Step: 334ms | Tot: 24s83ms | Loss: 0.707 | Acc: 53.852% (5997/11136) 87/169  [=================================>...............................]  Step: 274ms | Tot: 24s357ms | Loss: 0.707 | Acc: 53.782% (6058/11264) 88/169  [=================================>...............................]  Step: 274ms | Tot: 24s631ms | Loss: 0.707 | Acc: 53.845% (6134/11392) 89/169  [==================================>..............................]  Step: 271ms | Tot: 24s902ms | Loss: 0.707 | Acc: 53.854% (6204/11520) 90/169  [==================================>..............................]  Step: 273ms | Tot: 25s176ms | Loss: 0.706 | Acc: 53.898% (6278/11648) 91/169  [===================================>.............................]  Step: 273ms | Tot: 25s450ms | Loss: 0.706 | Acc: 53.966% (6355/11776) 92/169  [===================================>.............................]  Step: 286ms | Tot: 25s737ms | Loss: 0.706 | Acc: 53.923% (6419/11904) 93/169  [===================================>.............................]  Step: 271ms | Tot: 26s8ms | Loss: 0.706 | Acc: 53.989% (6496/12032) 94/169  [====================================>............................]  Step: 267ms | Tot: 26s276ms | Loss: 0.705 | Acc: 53.988% (6565/12160) 95/169  [====================================>............................]  Step: 270ms | Tot: 26s547ms | Loss: 0.705 | Acc: 54.053% (6642/12288) 96/169  [====================================>............................]  Step: 269ms | Tot: 26s816ms | Loss: 0.705 | Acc: 54.172% (6726/12416) 97/169  [=====================================>...........................]  Step: 269ms | Tot: 27s86ms | Loss: 0.705 | Acc: 54.106% (6787/12544) 98/169  [=====================================>...........................]  Step: 266ms | Tot: 27s353ms | Loss: 0.705 | Acc: 54.104% (6856/12672) 99/169  [======================================>..........................]  Step: 268ms | Tot: 27s622ms | Loss: 0.704 | Acc: 54.125% (6928/12800) 100/169  [======================================>..........................]  Step: 270ms | Tot: 27s892ms | Loss: 0.704 | Acc: 54.200% (7007/12928) 101/169  [======================================>..........................]  Step: 267ms | Tot: 28s160ms | Loss: 0.704 | Acc: 54.197% (7076/13056) 102/169  [=======================================>.........................]  Step: 270ms | Tot: 28s431ms | Loss: 0.704 | Acc: 54.232% (7150/13184) 103/169  [=======================================>.........................]  Step: 271ms | Tot: 28s703ms | Loss: 0.703 | Acc: 54.222% (7218/13312) 104/169  [========================================>........................]  Step: 274ms | Tot: 28s977ms | Loss: 0.703 | Acc: 54.271% (7294/13440) 105/169  [========================================>........................]  Step: 267ms | Tot: 29s245ms | Loss: 0.703 | Acc: 54.348% (7374/13568) 106/169  [========================================>........................]  Step: 310ms | Tot: 29s556ms | Loss: 0.702 | Acc: 54.381% (7448/13696) 107/169  [=========================================>.......................]  Step: 270ms | Tot: 29s826ms | Loss: 0.702 | Acc: 54.434% (7525/13824) 108/169  [=========================================>.......................]  Step: 432ms | Tot: 30s259ms | Loss: 0.702 | Acc: 54.415% (7592/13952) 109/169  [=========================================>.......................]  Step: 267ms | Tot: 30s526ms | Loss: 0.702 | Acc: 54.425% (7663/14080) 110/169  [==========================================>......................]  Step: 288ms | Tot: 30s814ms | Loss: 0.702 | Acc: 54.406% (7730/14208) 111/169  [==========================================>......................]  Step: 269ms | Tot: 31s83ms | Loss: 0.702 | Acc: 54.415% (7801/14336) 112/169  [===========================================>.....................]  Step: 268ms | Tot: 31s352ms | Loss: 0.702 | Acc: 54.418% (7871/14464) 113/169  [===========================================>.....................]  Step: 265ms | Tot: 31s618ms | Loss: 0.702 | Acc: 54.413% (7940/14592) 114/169  [===========================================>.....................]  Step: 269ms | Tot: 31s887ms | Loss: 0.702 | Acc: 54.463% (8017/14720) 115/169  [============================================>....................]  Step: 309ms | Tot: 32s197ms | Loss: 0.702 | Acc: 54.492% (8091/14848) 116/169  [============================================>....................]  Step: 267ms | Tot: 32s464ms | Loss: 0.702 | Acc: 54.507% (8163/14976) 117/169  [=============================================>...................]  Step: 267ms | Tot: 32s731ms | Loss: 0.701 | Acc: 54.575% (8243/15104) 118/169  [=============================================>...................]  Step: 269ms | Tot: 33s | Loss: 0.701 | Acc: 54.563% (8311/15232) 119/169  [=============================================>...................]  Step: 266ms | Tot: 33s267ms | Loss: 0.701 | Acc: 54.551% (8379/15360) 120/169  [==============================================>..................]  Step: 268ms | Tot: 33s535ms | Loss: 0.701 | Acc: 54.636% (8462/15488) 121/169  [==============================================>..................]  Step: 267ms | Tot: 33s802ms | Loss: 0.700 | Acc: 54.675% (8538/15616) 122/169  [==============================================>..................]  Step: 267ms | Tot: 34s70ms | Loss: 0.700 | Acc: 54.643% (8603/15744) 123/169  [===============================================>.................]  Step: 266ms | Tot: 34s336ms | Loss: 0.701 | Acc: 54.599% (8666/15872) 124/169  [===============================================>.................]  Step: 267ms | Tot: 34s604ms | Loss: 0.700 | Acc: 54.625% (8740/16000) 125/169  [================================================>................]  Step: 268ms | Tot: 34s872ms | Loss: 0.700 | Acc: 54.656% (8815/16128) 126/169  [================================================>................]  Step: 267ms | Tot: 35s140ms | Loss: 0.700 | Acc: 54.583% (8873/16256) 127/169  [================================================>................]  Step: 266ms | Tot: 35s407ms | Loss: 0.700 | Acc: 54.596% (8945/16384) 128/169  [=================================================>...............]  Step: 282ms | Tot: 35s689ms | Loss: 0.700 | Acc: 54.645% (9023/16512) 129/169  [=================================================>...............]  Step: 267ms | Tot: 35s957ms | Loss: 0.700 | Acc: 54.633% (9091/16640) 130/169  [==================================================>..............]  Step: 267ms | Tot: 36s225ms | Loss: 0.699 | Acc: 54.699% (9172/16768) 131/169  [==================================================>..............]  Step: 266ms | Tot: 36s492ms | Loss: 0.699 | Acc: 54.735% (9248/16896) 132/169  [==================================================>..............]  Step: 268ms | Tot: 36s760ms | Loss: 0.699 | Acc: 54.729% (9317/17024) 133/169  [===================================================>.............]  Step: 273ms | Tot: 37s33ms | Loss: 0.699 | Acc: 54.781% (9396/17152) 134/169  [===================================================>.............]  Step: 274ms | Tot: 37s308ms | Loss: 0.699 | Acc: 54.850% (9478/17280) 135/169  [===================================================>.............]  Step: 271ms | Tot: 37s579ms | Loss: 0.699 | Acc: 54.808% (9541/17408) 136/169  [====================================================>............]  Step: 270ms | Tot: 37s850ms | Loss: 0.699 | Acc: 54.841% (9617/17536) 137/169  [====================================================>............]  Step: 268ms | Tot: 38s119ms | Loss: 0.699 | Acc: 54.869% (9692/17664) 138/169  [=====================================================>...........]  Step: 270ms | Tot: 38s389ms | Loss: 0.698 | Acc: 54.901% (9768/17792) 139/169  [=====================================================>...........]  Step: 268ms | Tot: 38s658ms | Loss: 0.699 | Acc: 54.877% (9834/17920) 140/169  [=====================================================>...........]  Step: 268ms | Tot: 38s926ms | Loss: 0.698 | Acc: 54.898% (9908/18048) 141/169  [======================================================>..........]  Step: 276ms | Tot: 39s202ms | Loss: 0.698 | Acc: 54.913% (9981/18176) 142/169  [======================================================>..........]  Step: 268ms | Tot: 39s470ms | Loss: 0.698 | Acc: 54.906% (10050/18304) 143/169  [=======================================================>.........]  Step: 271ms | Tot: 39s742ms | Loss: 0.698 | Acc: 54.942% (10127/18432) 144/169  [=======================================================>.........]  Step: 270ms | Tot: 40s13ms | Loss: 0.698 | Acc: 54.930% (10195/18560) 145/169  [=======================================================>.........]  Step: 271ms | Tot: 40s284ms | Loss: 0.698 | Acc: 54.966% (10272/18688) 146/169  [========================================================>........]  Step: 308ms | Tot: 40s593ms | Loss: 0.698 | Acc: 54.932% (10336/18816) 147/169  [========================================================>........]  Step: 286ms | Tot: 40s880ms | Loss: 0.698 | Acc: 54.957% (10411/18944) 148/169  [========================================================>........]  Step: 269ms | Tot: 41s149ms | Loss: 0.698 | Acc: 54.976% (10485/19072) 149/169  [=========================================================>.......]  Step: 266ms | Tot: 41s416ms | Loss: 0.697 | Acc: 54.990% (10558/19200) 150/169  [=========================================================>.......]  Step: 269ms | Tot: 41s686ms | Loss: 0.697 | Acc: 55.024% (10635/19328) 151/169  [==========================================================>......]  Step: 266ms | Tot: 41s952ms | Loss: 0.697 | Acc: 55.058% (10712/19456) 152/169  [==========================================================>......]  Step: 270ms | Tot: 42s222ms | Loss: 0.697 | Acc: 55.050% (10781/19584) 153/169  [==========================================================>......]  Step: 267ms | Tot: 42s489ms | Loss: 0.697 | Acc: 55.134% (10868/19712) 154/169  [===========================================================>.....]  Step: 267ms | Tot: 42s757ms | Loss: 0.696 | Acc: 55.146% (10941/19840) 155/169  [===========================================================>.....]  Step: 265ms | Tot: 43s23ms | Loss: 0.696 | Acc: 55.133% (11009/19968) 156/169  [============================================================>....]  Step: 269ms | Tot: 43s293ms | Loss: 0.696 | Acc: 55.130% (11079/20096) 157/169  [============================================================>....]  Step: 268ms | Tot: 43s561ms | Loss: 0.696 | Acc: 55.133% (11150/20224) 158/169  [============================================================>....]  Step: 268ms | Tot: 43s829ms | Loss: 0.696 | Acc: 55.179% (11230/20352) 159/169  [=============================================================>...]  Step: 270ms | Tot: 44s100ms | Loss: 0.696 | Acc: 55.190% (11303/20480) 160/169  [=============================================================>...]  Step: 269ms | Tot: 44s369ms | Loss: 0.696 | Acc: 55.144% (11364/20608) 161/169  [=============================================================>...]  Step: 268ms | Tot: 44s638ms | Loss: 0.696 | Acc: 55.170% (11440/20736) 162/169  [==============================================================>..]  Step: 269ms | Tot: 44s908ms | Loss: 0.696 | Acc: 55.157% (11508/20864) 163/169  [==============================================================>..]  Step: 273ms | Tot: 45s181ms | Loss: 0.696 | Acc: 55.183% (11584/20992) 164/169  [===============================================================>.]  Step: 303ms | Tot: 45s485ms | Loss: 0.696 | Acc: 55.232% (11665/21120) 165/169  [===============================================================>.]  Step: 280ms | Tot: 45s765ms | Loss: 0.695 | Acc: 55.285% (11747/21248) 166/169  [===============================================================>.]  Step: 266ms | Tot: 46s32ms | Loss: 0.695 | Acc: 55.300% (11821/21376) 167/169  [================================================================>]  Step: 267ms | Tot: 46s299ms | Loss: 0.695 | Acc: 55.348% (11902/21504) 168/169  [================================================================>]  Step: 55ms | Tot: 46s355ms | Loss: 0.695 | Acc: 55.339% (11909/21520) 169/169 
Traceback (most recent call last):
  File "/home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/predict.py", line 127, in <module>
    test_valid_measure()      
    ^^^^^^^^^^^^^^^^^^^^
  File "/home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/predict.py", line 101, in test_valid_measure
    trainloss,testloss, acc = train_valid(epoch) 
                              ^^^^^^^^^^^^^^^^^^
  File "/home/Student/s4737925/Project/PatternAnalysis-2023/recognition/ADNI_TRANSFORMER_47379251/train.py", line 239, in train_valid
    for batch_idx, (inputs, targets) in enumerate(validloader):
                                                  ^^^^^^^^^^^
NameError: name 'validloader' is not defined. Did you mean: 'trainloader'?
