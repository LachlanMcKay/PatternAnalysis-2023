{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (11,11)\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "mean = 0.5\n",
    "std = 0.5\n",
    "external_drive = \"D:/MNIST\"\n",
    "dataset = MNIST(external_drive, transform=T.Compose([T.ToTensor(), T.Normalize((mean,), (std,))]), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class Scaled_Act(nn.Module):\n",
    "    to_str = {'Sigmoid' : 'sigmoid', 'ReLU': 'relu', 'Tanh' : 'tanh', 'LeakyReLU': 'leaky_relu'}\n",
    "    def __init__(self, act, scale = None):\n",
    "        super().__init__()\n",
    "        self.act = act\n",
    "        act_name = Scaled_Act.to_str.get(act._get_name(), act._get_name())\n",
    "        param = getattr(act, 'negative_slope', None)\n",
    "        self.scale = scale if scale else torch.nn.init.calculate_gain(act_name, param)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.scale*self.act(input)\n",
    "\n",
    "class Equal_LR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_norm(module, weight):\n",
    "        mode = 'fan_in'\n",
    "        if hasattr(module, 'transposed') and module.transposed:\n",
    "            mode = 'fan_out'\n",
    "        return torch.nn.init._calculate_correct_fan(weight, mode)\n",
    "\n",
    "\n",
    "    def scale_weight(self, module, input):\n",
    "        setattr(module, self.name, module.scale*module.weight_orig)\n",
    "\n",
    "    def fn(self, module):\n",
    "        try:\n",
    "            weight = getattr(module, self.name)\n",
    "            module.scale = 1/np.sqrt(Equal_LR.compute_norm(module, weight))\n",
    "            if isinstance(weight, torch.nn.Parameter):\n",
    "                # register new parameter -- unscaled weight\n",
    "                module.weight_orig = nn.Parameter(weight.clone()/module.scale)\n",
    "                # delete old parameter\n",
    "                del module._parameters[self.name]\n",
    "            else:\n",
    "                # register new buffer -- unscaled weight\n",
    "                module.register_buffer('weight_orig', weight.clone()/module.scale)\n",
    "                # delete old buffer\n",
    "                del module._buffers[self.name]\n",
    "            module.equalize = module.register_forward_pre_hook(self.scale_weight)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def __call__(self, module):\n",
    "        new_module = deepcopy(module)\n",
    "        new_module.apply(self.fn)\n",
    "        return new_module\n",
    "\n",
    "def parameters_to_buffers(m):\n",
    "    params = m._parameters.copy()\n",
    "    m._parameters.clear()\n",
    "    for n,p in params.items():\n",
    "        m.register_buffer(n, p.data)\n",
    "\n",
    "def grid(array, ncols=8):\n",
    "    array = np.pad(array, [(0,0),(1,1),(1,1),(0,0)], 'constant')\n",
    "    nindex, height, width, intensity = array.shape\n",
    "    ncols = min(nindex, ncols)\n",
    "    nrows = (nindex+ncols-1)//ncols\n",
    "    r = nrows*ncols - nindex # remainder\n",
    "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "    arr = np.concatenate([array]+[np.zeros([1,height,width,intensity])]*r)\n",
    "    result = (arr.reshape(nrows, ncols, height, width, intensity)\n",
    "            .swapaxes(1,2)\n",
    "            .reshape(height*nrows, width*ncols, intensity))\n",
    "    return np.pad(result, [(1,1),(1,1),(0,0)], 'constant')\n",
    "\n",
    "class NextDataLoader(torch.utils.data.DataLoader):\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            return next(self.iterator)\n",
    "        except:\n",
    "            self.iterator = self.__iter__()\n",
    "            return next(self.iterator)\n",
    "\n",
    "def to_tensor(obj, device='cuda'):\n",
    "    if obj.shape[-1] != 3 and obj.shape[-1] != 1:\n",
    "        obj = np.expand_dims(obj,-1)\n",
    "    if obj.ndim < 4:\n",
    "        obj = np.expand_dims(obj,0)\n",
    "    t = torch.tensor(np.moveaxis(obj,-1,-3), dtype=torch.float, device=device)\n",
    "    return t\n",
    "\n",
    "def to_img(obj):\n",
    "    array = np.moveaxis(obj.data.cpu().numpy(),-3,-1)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network functions\n",
    "class Modulated_Conv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, latent_size,\n",
    "                 demodulate=True, bias=True, stride=1, padding=0, dilation=1, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                        padding, dilation, groups=1,\n",
    "                        bias=bias, padding_mode='zeros')\n",
    "        self.demodulate = demodulate\n",
    "        # style mapping\n",
    "        self.style = nn.Linear(latent_size, in_channels)\n",
    "        # required shape might be different in transposed conv\n",
    "        self.s_broadcast_view = (-1,1,self.in_channels,1,1)\n",
    "        self.in_channels_dim = 2\n",
    "\n",
    "\n",
    "    def convolve(self,x,w,groups):\n",
    "        # bias would be added later\n",
    "        return F.conv2d(x, w, None, self.stride, self.padding, self.dilation, groups=groups)\n",
    "\n",
    "\n",
    "    def forward(self, x, v):\n",
    "        N, in_channels, H, W = x.shape\n",
    "\n",
    "        # new minibatch dim: (ch dims, K, K) -> (1, ch dims, K, K)\n",
    "        w = self.weight.unsqueeze(0)\n",
    "\n",
    "        # compute styles: (N, C_in)\n",
    "        s = self.style(v) + 1\n",
    "\n",
    "        # modulate: (N, ch dims, K, K)\n",
    "        w = s.view(self.s_broadcast_view)*w\n",
    "\n",
    "        # demodulate\n",
    "        if self.demodulate:\n",
    "            sigma = torch.sqrt((w**2).sum(dim=[self.in_channels_dim,3,4],keepdim=True) + 1e-8)\n",
    "            w = w/sigma\n",
    "\n",
    "        # reshape x: (N, C_in, H, W) -> (1, N*C_in, H, W)\n",
    "        x = x.view(1, -1, H, W)\n",
    "\n",
    "        # reshape w: (N, C_out, C_in, K, K) -> (N*C_out, C_in, K, K) for common conv\n",
    "        #            (N, C_in, C_out, K, K) -> (N*C_in, C_out, K, K) for transposed conv\n",
    "        w = w.view(-1, w.shape[2], w.shape[3], w.shape[4])\n",
    "\n",
    "        # use groups so that each sample in minibatch has it's own conv,\n",
    "        # conv weights are concatenated along dim=0\n",
    "        out = self.convolve(x,w,N)\n",
    "\n",
    "        # reshape back to minibatch.\n",
    "        out = out.view(N,-1,out.shape[2],out.shape[3])\n",
    "\n",
    "        # add bias\n",
    "        if not self.bias is None:\n",
    "            out += self.bias.view(1, self.bias.shape[0], 1, 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Up_Mod_Conv(Modulated_Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, latent_size,\n",
    "                demodulate=True, bias=True, factor=2):\n",
    "        assert (kernel_size % 2 == 1)\n",
    "        padding = (max(kernel_size-factor,0)+1)//2\n",
    "        super().__init__(in_channels, out_channels, kernel_size, latent_size, demodulate, bias,\n",
    "                        stride=factor, padding=padding)\n",
    "        self.output_padding = torch.nn.modules.utils._pair(2*padding - kernel_size + factor)\n",
    "        # transpose as expected in F.conv_transpose2d\n",
    "        self.weight = nn.Parameter(self.weight.transpose(0,1).contiguous())\n",
    "        self.transposed = True\n",
    "        # taking into account transposition\n",
    "        self.s_broadcast_view = (-1,self.in_channels,1,1,1)\n",
    "        self.in_channels_dim = 1\n",
    "\n",
    "    def convolve(self, x, w, groups):\n",
    "        return F.conv_transpose2d(x, w, None, self.stride, self.padding, self.output_padding, groups, self.dilation)\n",
    "\n",
    "\n",
    "class Down_Mod_Conv(Modulated_Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, latent_size,\n",
    "                demodulate=True, bias=True, factor=2):\n",
    "        assert (kernel_size % 2 == 1)\n",
    "        padding = kernel_size//2\n",
    "        super().__init__(in_channels, out_channels, kernel_size, latent_size, demodulate, bias,\n",
    "                        stride=factor, padding=padding)\n",
    "\n",
    "    def convolve(self, x, w, groups):\n",
    "        return F.conv2d(x, w, None, self.stride, self.padding, self.dilation, groups=groups)\n",
    "\n",
    "\n",
    "class Down_Conv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                bias=True, factor=2):\n",
    "        assert (kernel_size % 2 == 1)\n",
    "        padding = kernel_size//2\n",
    "        super().__init__(in_channels, out_channels, kernel_size, factor, padding, bias=True)\n",
    "\n",
    "    def convolve(self, x):\n",
    "        return F.conv2d(x, w, None, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.noise_strength = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x, input_noise=None):\n",
    "        if input_noise is None:\n",
    "            input_noise = torch.randn(x.shape[0],1,x.shape[2],x.shape[3], device=x.device)\n",
    "        noise = self.noise_strength*input_noise\n",
    "        return x + noise\n",
    "\n",
    "class Mapping(nn.Module):\n",
    "    def __init__(self, n_layers, latent_size, nonlinearity, normalize=True):\n",
    "        super().__init__()\n",
    "        self.normalize = normalize\n",
    "        self.layers = []\n",
    "        for idx in range(n_layers):\n",
    "            layer = nn.Linear(latent_size, latent_size)\n",
    "            self.add_module(str(idx), layer)\n",
    "            self.layers.append(layer)\n",
    "            self.layers.append(nonlinearity)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.normalize:\n",
    "            input = input/torch.sqrt((input**2).mean(dim=1, keepdim=True) + 1e-8)\n",
    "        for module in self.layers:\n",
    "            input = module(input)\n",
    "        return input\n",
    "\n",
    "\n",
    "class G_Block(nn.Module):\n",
    "    def __init__(self, in_fmaps, out_fmaps, kernel_size, latent_size, nonlinearity, factor=2, img_channels=3):\n",
    "        super().__init__()\n",
    "        inter_fmaps = (in_fmaps + out_fmaps)//2\n",
    "        self.upconv = Up_Mod_Conv(in_fmaps, inter_fmaps, kernel_size, latent_size,\n",
    "                                    factor=factor)\n",
    "        self.conv = Modulated_Conv2d(inter_fmaps, out_fmaps, kernel_size, latent_size,\n",
    "                                    padding=kernel_size//2)\n",
    "        self.noise = Noise()\n",
    "        self.noise2 = Noise()\n",
    "        self.to_channels = Modulated_Conv2d(out_fmaps, img_channels, kernel_size=1,\n",
    "                                    latent_size=latent_size, demodulate = False)\n",
    "        self.upsample = nn.Upsample(scale_factor=factor, mode='bilinear', align_corners=False)\n",
    "        self.act = nonlinearity\n",
    "\n",
    "    def forward(self, x, v, y=None, input_noises=None):\n",
    "        x = self.noise(self.upconv(x,v), None if (input_noises is None) else input_noises[:,0])\n",
    "        x = self.act(x)\n",
    "        x = self.noise2(self.conv(x,v), None if (input_noises is None) else input_noises[:,1])\n",
    "        x = self.act(x)\n",
    "        if not y is None:\n",
    "            y = self.upsample(y)\n",
    "        else:\n",
    "            y = 0\n",
    "        y = y + self.to_channels(x,v)\n",
    "        return x, y\n",
    "\n",
    "class D_Block(nn.Module):\n",
    "    def __init__(self, in_fmaps, out_fmaps, kernel_size, nonlinearity, factor=2):\n",
    "        super().__init__()\n",
    "        inter_fmaps = (in_fmaps + out_fmaps)//2\n",
    "        self.conv = nn.Conv2d(in_fmaps, inter_fmaps, kernel_size, padding=kernel_size//2)\n",
    "        self.downconv = Down_Conv2d(inter_fmaps, out_fmaps, kernel_size, factor=factor)\n",
    "        self.skip = Down_Conv2d(in_fmaps, out_fmaps, kernel_size=1, factor=factor)\n",
    "        self.act = nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = x\n",
    "        x = self.conv(x)\n",
    "        x = self.act(x)\n",
    "        x = self.downconv(x)\n",
    "        x = self.act(x)\n",
    "        t = self.skip(t)\n",
    "        return (x + t)/ np.sqrt(2)\n",
    "\n",
    "\n",
    "class Minibatch_Stddev(nn.Module):\n",
    "    def __init__(self, group_size=4):\n",
    "        super().__init__()\n",
    "        self.group_size = group_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x.shape\n",
    "        t = x.view(self.group_size, -1, s[1], s[2], s[3])\n",
    "        t = t - t.mean(dim=0, keepdim=True)\n",
    "        t = torch.sqrt((t**2).mean(dim=0) + 1e-8)\n",
    "        t = t.mean(dim=[1,2,3], keepdim=True) # [N/G,1,1,1]\n",
    "        t = t.repeat(self.group_size,1,1,1).expand(x.shape[0],1,*x.shape[2:])\n",
    "        return torch.cat((x,t),dim=1)\n",
    "def G_logistic_ns(fake_logits):\n",
    "    return -F.logsigmoid(fake_logits).mean() # -log(D(G(z)))\n",
    "\n",
    "\n",
    "def D_logistic(real_logits, fake_logits):\n",
    "    return torch.mean(-F.logsigmoid(real_logits) + F.softplus(fake_logits)) # -log(D(x)) - log(1-D(G(z)))\n",
    "\n",
    "def R1_reg(real_imgs, real_logits):\n",
    "    grads = torch.autograd.grad(real_logits.sum(), real_imgs, create_graph=True)[0]\n",
    "    return torch.mean((grads**2).sum(dim=[1,2,3]))\n",
    "\n",
    "class Path_length_loss(nn.Module):\n",
    "    def __init__(self, decay=0.01):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "        self.avg = 0\n",
    "\n",
    "    def forward(self, dlatent, gen_out):\n",
    "        # Compute |J*y|.\n",
    "        noise = torch.randn(gen_out.shape, device=gen_out.device)/np.sqrt(np.prod(gen_out.shape[2:])) #[N,Channels,H,W]\n",
    "        grads = torch.autograd.grad((gen_out * noise).sum(), dlatent, create_graph=True)[0]  #[N, num_layers, dlatent_size]\n",
    "        lengths = torch.sqrt((grads**2).mean(2).sum(1)) #[N]\n",
    "        # Update exp average. Lengths are detached\n",
    "        self.avg = self.decay*torch.mean(lengths.detach()) + (1-self.decay)*self.avg\n",
    "        return torch.mean((lengths - self.avg)**2)\n",
    "\n",
    "\n",
    "def Noise_reg(noise_maps, min_res=8):\n",
    "    loss = 0\n",
    "    for nmap in noise_maps:\n",
    "        res = nmap.shape[-1]\n",
    "        while res > 8:\n",
    "            loss += ( torch.mean(nmap * nmap.roll(shifts=1, dims=-1), dim=[-1,-2])**2\n",
    "                    + torch.mean(nmap * nmap.roll(shifts=1, dims=-2), dim=[-1,-2])**2 ).sum()\n",
    "            nmap = F.avg_pool2d(nmap.squeeze(), 2)\n",
    "            res = res//2\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
